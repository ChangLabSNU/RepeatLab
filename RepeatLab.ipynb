{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmzAssY_L_4H"
      },
      "source": [
        "<img src=\"https://github.com/ChangLabSNU/RepeatLab/blob/main/RepeatLab_logo.png?raw=true\" height=\"300\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "# RepeatLab: Automated Long-Read Sequencing Analysis for Repeat Expansion Disorders\n",
        "\n",
        "Welcome to RepeatLab! This tool helps you analyze long-read DNA sequencing data from Oxford Nanopore to estimate repeat expansion sizes and structures. It's particularly useful for diagnosing repeat expansion diseases such as myotonic dystrophy (DM1/DM2), Huntington's disease-like syndromes, and other related disorders.\n",
        "\n",
        "### What you'll need:\n",
        "- Long-read sequencing data (POD5, FAST5, or FASTQ format)\n",
        "- Data stored in your Google Drive\n",
        "- About 20-30 minutes for the complete analysis\n",
        "\n",
        "### Quick navigation:\n",
        "- **New to RepeatLab?** Follow the three starred steps (⭐) below\n",
        "- **Need help?** Jump to the [detailed instructions](#Instructions) at the bottom\n",
        "- **Ready to start?** Click `Runtime` → `Run all` after filling in your parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBPXn2NvyC9H"
      },
      "source": [
        "## Quick Start Guide <a name=\"Quick Start\"></a>\n",
        "\n",
        "Follow these three simple steps to run your analysis:\n",
        "\n",
        "⭐ **Step 1:** Configure your input data location and parameters (in the cell below)\n",
        "\n",
        "⭐ **Step 2:** Specify your sample name and target gene\n",
        "\n",
        "⭐ **Step 3:** Run the entire notebook (`Runtime` → `Run all` or press `Ctrl/Cmd + F9`)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "96ZW25TW4ino"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ⭐ **1. Copy the folder containing POD5, FAST5, or FASTQ files into your Google Drive, and write down the location below.**\n",
        "#@markdown - POD5 or FAST5 file format is recommended as input.\n",
        "#@markdown - The `data_dir` must be under the `MyDrive` directory.  <a name=\"data_dir\"></a>\n",
        "\n",
        "data_type = \"pod5\" #@param [\"pod5\", \"fast5\", \"fastq\"]\n",
        "data_dir = \"NA03697-test/\" #@param {type:\"string\"}\n",
        "#output_dir = \"Colab Notebooks/outputs/test\" #@param {type:\"string\"}\n",
        "pore_type = \"r9.4.1\" #@param [\"r9.4.1\", \"r10.4.1\"]\n",
        "\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ⭐ **2. Write down your sample name and target gene name. Sample name will be printed in your report.**\n",
        "\n",
        "\n",
        "sample_name = \"NA03697\" #@param {type:\"string\"}\n",
        "target_gene = \"DMPK\" #@param [\"DMPK\", \"CNBP\", \"NOP56\", \"None\"]\n",
        "target_gene_lower = f'{target_gene}'.lower()\n",
        "\n",
        "NEW_TARGET = False\n",
        "#@markdown - If there is NO target you want, then add new targets <a href=\"#Add Target\">below</a>.\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown ⭐ **3. Click the button `Runtime` tab > `Run all` (or just hit '`command`/`control` + `F9`' as keyboard shortcut).**\n",
        "#@markdown\n",
        "#@markdown - Sign in to your own Google account if pop-up appears or press `Continue` if the account is already connected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmqZziacTLnO"
      },
      "source": [
        "## Custom option setting\n",
        "##### Click to expand custom & advanced setting cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "26yC2_gySe6n"
      },
      "outputs": [],
      "source": [
        "#@title (Advanced) Input parameters\n",
        "#@markdown You can change Dorado basecaller version. You can just keep the defualt options for your first run.\n",
        "\n",
        "dorado_version = \"0.4.1\" #@param [\"0.3.0\", \"0.3.1\", \"0.3.2\", \"0.4.0\", \"0.4.1\"]\n",
        "\n",
        "if pore_type == 'r9.4.1':\n",
        "  dorado_model = \"dna_r9.4.1_e8_sup@v3.6\"\n",
        "  dorado_rough_model = \"dna_r9.4.1_e8_fast@v3.4\"\n",
        "  dorado_original_model = \"dna_r9.4.1_e8_sup@v3.3\"\n",
        "  if dorado_version.startswith('0.3'):\n",
        "    dorado_5mC_model = \"dna_r9.4.1_e8_sup@v3.3_5mCG@v0\"\n",
        "  elif dorado_version.startswith('0.4'):\n",
        "    dorado_5mC_model = \"dna_r9.4.1_e8_sup@v3.3_5mCG@v0.1\"\n",
        "\n",
        "#@markdown Translocation speed information is needed only for R10.4.1 pore. Just ignore this section for R9.4.1.\n",
        "if pore_type == 'r10.4.1':\n",
        "  translocation_speed = \"260bps\" #@param [\"260bps\", \"400bps\"]\n",
        "  if translocation_speed == \"260bps\":\n",
        "    dorado_model = \"dna_r10.4.1_e8.2_260bps_sup@v4.1.0\"\n",
        "    dorado_rough_model = \"dna_r10.4.1_e8.2_260bps_fast@v4.1.0\"\n",
        "    dorado_5mC_model = \"dna_r10.4.1_e8.2_260bps_sup@v3.5.2_5mCG@v2\"\n",
        "    dorado_original_model = \"dna_r10.4.1_e8.2_260bps_sup@v3.5.2\"\n",
        "  elif translocation_speed == \"400bps\":\n",
        "    dorado_model = \"dna_r10.4.1_e8.2_400bps_sup@v4.1.0\"\n",
        "    dorado_rough_model = \"dna_r10.4.1_e8.2_400bps_fast@v4.1.0\"\n",
        "    dorado_5mC_model = \"dna_r10.4.1_e8.2_400bps_sup@v3.5.2_5mCG@v2\"\n",
        "    dorado_original_model = \"dna_r10.4.1_e8.2_400bps_sup@v3.5.2\"\n",
        "\n",
        "# dorado_model = \"dna_r9.4.1_e8_sup@v3.6\" #@param [\"dna_r9.4.1_e8_fast@v3.4\", \"dna_r9.4.1_e8_hac@v3.3\", \"dna_r9.4.1_e8_sup@v3.3\", \"dna_r9.4.1_e8_sup@v3.6\", \"dna_r10.4.1_e8.2_260bps_fast@v4.1.0\", \"dna_r10.4.1_e8.2_260bps_hac@v4.1.0\", \"dna_r10.4.1_e8.2_260bps_sup@v4.1.0\", \"dna_r10.4.1_e8.2_400bps_fast@v4.1.0\", \"dna_r10.4.1_e8.2_400bps_hac@v4.1.0\", \"dna_r10.4.1_e8.2_400bps_sup@v4.1.0\"] {allow-input: true}\n",
        "# dorado_rough_model =\n",
        "# dorado_5mC_model = \"dna_r9.4.1_e8_sup@v3.3_5mCG@v0\" #@param [\"dna_r9.4.1_e8_fast@v3.4_5mCG@v0\", \"dna_r9.4.1_e8_hac@v3.3_5mCG@v0\", \"dna_r9.4.1_e8_sup@v3.3_5mCG@v0\"]\n",
        "# dorado_original_model = dorado_5mC_model[:-8]\n",
        "\n",
        "minimap2_options = \"-w 20 -s 40 -k 13\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "baQlvLYcBA_6"
      },
      "outputs": [],
      "source": [
        "#@title (Advanced) Barcode demultiplexing\n",
        "#@markdown - If the sample data is multiplexed using barcodes, check this box and choose the kit and the barcode number.\n",
        "#@markdown - Dorado version >= 0.4.0 is needed for barcode demultiplexing. Please adjust the `dorado_version` at the upper cell for use.\n",
        "\n",
        "barcode_multiplexing = False #@param {type:\"boolean\"}\n",
        "barcode_kit = \"EXP-NBD104\" #@param [\"EXP-NBD103\", \"EXP-NBD104\", \"EXP-NBD114\",\"EXP-NBD196\",\"EXP-PBC001\", \"EXP-PBC096\", \"SQK-16S024\", \"SQK-16S114-24\", \"SQK-LWB001\", \"SQK-MLK111-96-XL\", \"SQK-MLK114-96-XL\", \"SQK-NBD111-24\",\"SQK-NBD111-96\",\"SQK-NBD112-24\", \"SQK-NBD112-96\", \"SQK-NBD114-24\", \"SQK-NBD114-96\", \"SQK-PBK004\", \"SQK-PCB109\", \"SQK-PCB110\", \"SQK-PCB111-24\", \"SQK-PCB114-24\", \"SQK-RAB201\", \"SQK-RAB204\", \"SQK-RBK001\", \"SQK-RBK004\", \"SQK-RBK110-96\", \"SQK-RBK111-24\", \"SQK-RBK111-96\", \"SQK-RBK112-24\", \"SQK-RBK112-96\", \"SQK-RBK114-24\", \"SQK-RBK114-96\", \"SQK-RLB001\", \"SQK-RPB004\", \"SQK-RPB114-24\", \"VSK-PTC001\", \"VSK-VMK001\", \"VSK-VMK004\", \"VSK-VPS001\"]\n",
        "barcode_number = 1 # @param {type:\"integer\"}\n",
        "if barcode_number < 10:\n",
        "  barcode_num = 'barcode0' + str(barcode_number)\n",
        "else:\n",
        "  barcode_num = 'barcode' + str(barcode_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tFDcAGVMwh5d"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Add a new target <a name=\"Add Target\"></a>\n",
        "#@markdown Check the box and fill in the repeat information if you want to use this as a new target which is not in the `target_gene` lists.\n",
        "NEW_TARGET = False #@param {type:\"boolean\"}\n",
        "if NEW_TARGET == True:\n",
        "  target_gene = \"\" #@param {type:\"string\"}\n",
        "  #@markdown Repeat location\n",
        "  chromosome = \"chr1\" #@param [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\", \"chr11\", \"chr12\", \"chr13\", \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\", \"chrX\", \"chrY\"]\n",
        "  start_position = 0 #@param {type:\"integer\"}\n",
        "  end_position = 0 #@param {type:\"integer\"}\n",
        "  strand = \"+\" #@param [\"+\", \"-\"]\n",
        "  copy_number = 0 #@param {type:\"integer\"}\n",
        "  #@markdown Repeat pattern\n",
        "  repeat_pattern = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Methylation rate check sites\n",
        "#@markdown - Write down the positions of the CpG sites for which you want to specifically calculate the methylation rate. The sites should be listed and separated by commas (,) without any spaces ( ).(ONLY sites without chromosome number)\n",
        "#@markdown\n",
        "#@markdown    (e.g. 45768652,45768667)\n",
        "\n",
        "#@markdown - If you want to designate each key regions with multiple CpG sites, you can make groups of loci. CpG sites within the same group should be separated by commas (,), and different groups should be separated by a single space ( ).\n",
        "#@markdown\n",
        "#@markdown    (e.g. 45768652,45768667,45768673 45770725,45770739 45769906,45769912,45769924)\n",
        "\n",
        "#@markdown - If you selected DMPK as a target gene, CpG sites have already been entered. You don't need to write any text.\n",
        "\n",
        "if target_gene == \"DMPK\":\n",
        "  methylation_key_positions = \"45768652,45768667,45768673,45768678,45768682,45768687 45770725,45770739,45770744,45770750,45770784,45770788 45769906,45769912,45769924,45769933,45769951,45769953\"\n",
        "  CTCF1_positions = \"45770307,45770328,45770332,45770342,45770348,45770371,45770381,45770385,45770390,45770408,45770415,45770417,45770429,45770436,45770455,45770463,45770469,45770495,45770497,45770501,45770512,45770515,45770525,45770537,45770540\"\n",
        "  CTCF2_positions = \"45769994,45770013,45770015,45770022,45770039,45770068,45770076,45770091,45770107,45770111,45770116\"\n",
        "else:\n",
        "  methylation_key_positions = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "zOqGqJubQSBf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjfLT4OkX4DJ"
      },
      "source": [
        "---\n",
        "## Part A: Environment Setup and Installation\n",
        "\n",
        "This section will set up all the necessary software and dependencies for RepeatLab. The installation process includes:\n",
        "- Connecting to your Google Drive\n",
        "- Installing required bioinformatics tools (Dorado, Minimap2, Samtools)\n",
        "- Setting up Python dependencies\n",
        "\n",
        "**⏱️ Expected time: 5-10 minutes**\n",
        "\n",
        "You don't need to do anything here after mounting your Google Drive —just let the cells run. Feel free to grab a coffee while the installation completes!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting Google Drive\n",
        "\n",
        "This step connects your Google Drive to this Colab notebook so RepeatLab can access your sequencing data files. You'll be prompted to authorize access—this is completely normal and secure."
      ],
      "metadata": {
        "id": "MvbkaGP72sqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u8j9-z1G02Px"
      },
      "outputs": [],
      "source": [
        "#@markdown Click the play button to mount your Google Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "import os, os.path\n",
        "\n",
        "DRIVE_PREFIX = '/content/drive'\n",
        "DRIVE_ROOT = os.path.join(DRIVE_PREFIX, 'MyDrive')\n",
        "WORK_DIR = os.path.join(DRIVE_ROOT, 'repeatlab')\n",
        "SYS_DIR = os.path.join(DRIVE_ROOT, 'repeatlab', 'sys')\n",
        "#OUTPUT_DIR = os.path.join(DRIVE_ROOT, output_dir)\n",
        "INPUT_DIR = os.path.join(DRIVE_ROOT, data_dir)\n",
        "OUTPUT_DIR_S = os.path.join(DRIVE_ROOT, 'repeatlab', 'analysis', f'{sample_name}')\n",
        "OUTPUT_DIR_T = os.path.join(DRIVE_ROOT, 'repeatlab', 'analysis', f'{sample_name}', f'{sample_name}-{target_gene}')\n",
        "\n",
        "if not os.path.isdir(DRIVE_ROOT):\n",
        "  drive.mount(DRIVE_PREFIX)\n",
        "\n",
        "if not os.path.isdir(INPUT_DIR):\n",
        "  raise FileNotFoundError(f\"Input directory {INPUT_DIR} is not accessible.\")\n",
        "\n",
        "if not os.path.isdir(SYS_DIR):\n",
        "  os.makedirs(SYS_DIR)\n",
        "\n",
        "if not os.path.isdir(OUTPUT_DIR_S):\n",
        "  os.makedirs(OUTPUT_DIR_S)\n",
        "\n",
        "if not os.path.isdir(OUTPUT_DIR_T):\n",
        "  os.makedirs(OUTPUT_DIR_T)\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up Python Environment\n",
        "\n",
        "RepeatLab uses Python for data processing and analysis. This cell installs the necessary Python packages and configures the environment paths. You'll see some package installation messages—this is normal."
      ],
      "metadata": {
        "id": "eREtfK-d289I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S4neh-U2Lwf-"
      },
      "outputs": [],
      "source": [
        "#@markdown Python environment configuration.\n",
        "\n",
        "import subprocess as sp\n",
        "\n",
        "try:\n",
        "  import pod5\n",
        "except ImportError:\n",
        "  sp.check_call(['pip', 'install', 'pod5==0.3.11'])\n",
        "  import pod5\n",
        "\n",
        "try:\n",
        "  import epi2melabs\n",
        "except ImportError:\n",
        "  sp.check_call(['pip', 'install', 'epi2melabs==0.0.59'])\n",
        "  import epi2melabs\n",
        "\n",
        "try:\n",
        "  import pyranges\n",
        "except ImportError:\n",
        "  sp.check_call(['pip', 'install', 'pyranges==0.1.2'])\n",
        "  import pyranges\n",
        "\n",
        "try:\n",
        "  import pysam\n",
        "except ImportError:\n",
        "  sp.check_call(['pip', 'install', 'pysam==0.22.1'])\n",
        "  import pysam\n",
        "\n",
        "try:\n",
        "  import alv\n",
        "except ImportError:\n",
        "  sp.check_call(['pip', 'install', 'alv==1.7.2'])\n",
        "  import alv\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.offsetbox as offsetbox\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from epi2melabs.notebook import InputForm, InputSpec\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from bokeh.layouts import gridplot\n",
        "from bokeh.models import Legend\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Core Dependencies\n",
        "\n",
        "RepeatLab requires several specialized bioinformatics tools:\n",
        "- **Samtools**: Tools for manipulating alignment files\n",
        "- **Minimap2**: Fast sequence aligner for long reads\n",
        "- **Dorado**: Oxford Nanopore's basecaller for processing raw sequencing data\n",
        "- **Modkit**: Oxford Nanopore's program for processing methylation profile data\n",
        "- **RepeatHMM**: A tool for counting repeats in long-read sequencing data (Liu et al., 2017; https://doi.org/10.1186/s13073-017-0456-7 )\n",
        "\n",
        "This cell will download and install these tools automatically."
      ],
      "metadata": {
        "id": "zPvqEdcv3S7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0lgtDg-qz6hf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@markdown Install dependencies.\n",
        "\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh > /dev/null 2>&1\n",
        "!bash miniconda.sh -b -p /root/conda > /dev/null 2>&1\n",
        "!rm miniconda.sh > /dev/null 2>&1\n",
        "!/root/conda/bin/conda init bash > /dev/null 2>&1\n",
        "\n",
        "CONDABIN = '/root/conda/bin'\n",
        "if CONDABIN not in os.environ['PATH'].split(':'):\n",
        "  os.environ['PATH'] += ':' + CONDABIN\n",
        "\n",
        "if not os.path.exists(os.path.join(CONDABIN, 'mamba')):\n",
        "  !conda install -y -n base -c conda-forge mamba > /dev/null 2>&1\n",
        "\n",
        "!/root/conda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main > /dev/null 2>&1\n",
        "!/root/conda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r > /dev/null 2>&1\n",
        "\n",
        "# Samtools, Minimap2\n",
        "if not os.path.isdir('/root/conda/envs/lab'):\n",
        "  !conda create -y -n lab samtools bedtools seqtk htslib openssl -c bioconda -c conda-forge > /dev/null 2>&1\n",
        "if not os.path.isdir('/root/conda/envs/ont_analysis'):\n",
        "  !conda create -y -n ont_analysis pomoxis -c bioconda > /dev/null 2>&1\n",
        "if not os.path.isdir('/root/conda/envs/minimap2'):\n",
        "  !conda create -y -n minimap2 minimap2 -c bioconda > /dev/null 2>&1\n",
        "\n",
        "lab_command_prefix = 'conda run -n lab --no-capture-output'\n",
        "ont_command_prefix = 'conda run -n ont_analysis --no-capture-output'\n",
        "minimap2_command_prefix = 'conda run -n minimap2 --no-capture-output'\n",
        "\n",
        "# Dorado\n",
        "dorado_top_dir = os.path.join(SYS_DIR, f'dorado-{dorado_version}-linux-x64')\n",
        "dorado = os.path.join(dorado_top_dir, 'bin', 'dorado')\n",
        "\n",
        "if not os.path.exists(dorado):\n",
        "  URL=f\"https://cdn.oxfordnanoportal.com/software/analysis/dorado-{dorado_version}-linux-x64.tar.gz\"\n",
        "  print(f\"=> Downloading dorado {dorado_version} from {URL}\")\n",
        "  !curl -L $URL | tar -C $SYS_DIR -xzf -\n",
        "  !mkdir \"$dorado_top_dir/basecalling_models\"\n",
        "  !chmod 755 $dorado\n",
        "\n",
        "if not os.path.exists(f'{dorado_top_dir}/basecalling_models/{dorado_model}'):\n",
        "  print(f'=> Downloading dorado basecalling model')\n",
        "  !$dorado download --model \"$dorado_model\" --directory \"$dorado_top_dir/basecalling_models\" > /dev/null 2>&1\n",
        "  !$dorado download --model \"$dorado_rough_model\" --directory \"$dorado_top_dir/basecalling_models\" > /dev/null 2>&1\n",
        "if not os.path.exists(f'{dorado_top_dir}/basecalling_models/{dorado_5mC_model}'):\n",
        "  print(f'=> Downloading dorado 5mC basecalling model')\n",
        "  !$dorado download --model \"$dorado_5mC_model\" --directory \"$dorado_top_dir/basecalling_models\" > /dev/null 2>&1\n",
        "  !$dorado download --model \"$dorado_original_model\" --directory \"$dorado_top_dir/basecalling_models\" > /dev/null 2>&1\n",
        "\n",
        "!chmod 755 $dorado\n",
        "!$dorado --version\n",
        "\n",
        "# Modkit\n",
        "modkit = os.path.join(SYS_DIR, 'dist', 'modkit')\n",
        "\n",
        "if not os.path.exists(modkit):\n",
        "  URL=\"https://github.com/nanoporetech/modkit/releases/download/v0.1.11/modkit_v0.1.11_centos7_x86_64.tar.gz\"\n",
        "  print(f'=> Downloading modit from {URL}')\n",
        "  !curl -L $URL | tar -C $SYS_DIR -xzf -\n",
        "  !chmod 755 $modkit\n",
        "!chmod 755 $modkit\n",
        "!$modkit --version\n",
        "\n",
        "# RepeatHMM\n",
        "REPEATHMM_DIR = os.path.join(SYS_DIR, 'RepeatHMM')\n",
        "if not os.path.isdir(REPEATHMM_DIR):\n",
        "  parentdir = os.path.dirname(REPEATHMM_DIR)\n",
        "  sp.check_call(f'cd {parentdir} && git clone https://github.com/WGLab/RepeatHMM', shell=True)\n",
        "\n",
        "import urllib\n",
        "import Path\n",
        "RHMM_ENV_SCRIPT = Path(REPEATHMM_DIR) / 'repeathmm-environment.diff'\n",
        "RHMM_ENV_SCRIPT_URL = 'https://github.com/ChangLabSNU/VaxLab/raw/refs/heads/main/patches/repeathmm-environment.diff'\n",
        "\n",
        "while not os.path.exists(RHMM_ENV_SCRIPT) or os.path.getsize(RHMM_ENV_SCRIPT) == 0:\n",
        "  print('=> Downloading env diff file..')\n",
        "  urllib.request.urlretrieve(RHMM_ENV_SCRIPT_URL, RHMM_ENV_SCRIPT)\n",
        "  sp.check_call('patch -p0 environment.yml repeathmm-environment.diff', shell=True)\n",
        "\n",
        "if not os.path.isdir('/root/conda/envs/rhmm'):\n",
        "  !cd $REPEATHMM_DIR && patch -p0 environment.yml repeathmm-environment.diff > /dev/null 2>&1\n",
        "  !conda env create -n rhmm -f $REPEATHMM_DIR/environment.yml > /dev/null 2>&1\n",
        "  !conda install -n rhmm -y swig > /dev/null 2>&1\n",
        "  !cd /root/conda/envs/rhmm/lib && ln -s libcrypto.so.1.1 libcrypto.so.1.0.0 > /dev/null 2>&1\n",
        "  !cd $REPEATHMM_DIR/bin/RepeatHMM_scripts/UnsymmetricPairAlignment && conda run -n rhmm --no-capture-output make > /dev/null 2>&1\n",
        "\n",
        "pattern_file = os.path.join(REPEATHMM_DIR, 'bin', 'reference_sts', 'hg38', 'hg38.predefined.pa')\n",
        "\n",
        "if NEW_TARGET == True:\n",
        "  new_target_line = target_gene.lower() + ',' + chromosome + ',' + str(start_position) + ',' + str(end_position) + ',' + repeat_pattern.upper() + ',' + strand+str(copy_number) + ',' + '' + ',' + ''\n",
        "  !echo $new_target_line >> $pattern_file\n",
        "  target_gene = target_gene.upper()\n",
        "\n",
        "RHMM_STRCT_SCRIPT = f'{REPEATHMM_DIR}/repeathmm-structure-dump.diff'\n",
        "RHMM_STRCT_SCRIPT_URL = 'https://github.com/ChangLabSNU/VaxLab/raw/refs/heads/main/patches/repeathmm-structure-dump.diff'\n",
        "while not os.path.exists(RHMM_STRCT_SCRIPT) or os.path.getsize(RHMM_STRCT_SCRIPT) == 0:\n",
        "  print('=> Downloading code diff file..')\n",
        "  urllib.request.urlretrieve(RHMM_STRCT_SCRIPT_URL, RHMM_STRCT_SCRIPT)\n",
        "  sp.check_call(f'cd {REPEATHMM_DIR}/bin && patch -p2 < ../repeathmm-structure-dump.diff')\n",
        "\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "di4kNakp5LY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the reference genome sequence\n",
        "\n",
        "- Download the reference genome sequence (GRCh38) from Gencode."
      ],
      "metadata": {
        "id": "-2VsrjzF5Pva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yFqyOEZCwKFh"
      },
      "outputs": [],
      "source": [
        "#@markdown Download reference genome sequence.\n",
        "\n",
        "REFERENCE_GENOME = 'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/GRCh38.p14.genome.fa.gz'\n",
        "\n",
        "!mkdir -p $WORK_DIR/references\n",
        "refgenome_fasta = os.path.join(WORK_DIR, 'references', 'genome.fa.gz')\n",
        "refgenome_fai = os.path.join(WORK_DIR, 'references', 'genome.fa.gz.fai')\n",
        "refgenome_index = os.path.join(WORK_DIR, 'references', 'genome.mm2.idx')\n",
        "refgenome_index_w30 = os.path.join(WORK_DIR, 'references', 'genome_w30.mm2.idx')\n",
        "\n",
        "if not os.path.exists(refgenome_fasta):\n",
        "  print('=> Downloading the reference genome')\n",
        "  !curl $REFERENCE_GENOME | zcat - | $lab_command_prefix \\\n",
        "    bgzip -c > $refgenome_fasta\n",
        "\n",
        "if not os.path.exists(refgenome_fai):\n",
        "  !$lab_command_prefix samtools faidx $refgenome_fasta\n",
        "\n",
        "if not os.path.exists(refgenome_index):\n",
        "  print('Building minimap2 index..')\n",
        "  !zcat $refgenome_fasta | $minimap2_command_prefix minimap2 -x map-ont $minimap2_options -d $refgenome_index /dev/stdin\n",
        "\n",
        "if not os.path.exists(refgenome_index_w30):\n",
        "  print('Building minimap2 index for rough alignment..')\n",
        "  !zcat $refgenome_fasta | $minimap2_command_prefix minimap2 -x map-ont -w 30 -k 20 -d $refgenome_index_w30 /dev/stdin\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB76A2WpZhpN"
      },
      "source": [
        "---\n",
        "## Part B: Data Processing & Target-Specific Analysis\n",
        "\n",
        "Now that the environment is set up, RepeatLab will process your sequencing data. This section converts raw electrical signals from the nanopore sequencer into DNA sequences (A, T, G, C) and aligns them to the genome sequence. After that, RepeatLab will focus on your gene of interest. This section aligns the sequenced reads to your target region and identifies reads that contain repeat expansions.\n",
        "\n",
        "The processing time depends on your data size, but typically takes 10-20 minutes for standard samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yyQGbIAWdpz_"
      },
      "outputs": [],
      "source": [
        "#@title Checking input directory\n",
        "\n",
        "#@markdown - Counting how many files in the input `data_dir`.\n",
        "\n",
        "# Check the FAST5 or FASTQ source dir for the existence and number of files.\n",
        "data_dir_top = os.path.join(DRIVE_ROOT, data_dir)\n",
        "if not os.path.isdir(data_dir_top):\n",
        "  raise FileNotFoundError(f'Data not accessible from {data_dir}')\n",
        "\n",
        "def count_input_files(topdir):\n",
        "  pod5_matches = []\n",
        "  fast5_matches = []\n",
        "  fastq_matches = []\n",
        "  fastq_zip_matches = []\n",
        "  for path, dirs, files in os.walk(topdir):\n",
        "    for f in files:\n",
        "      if f.lower().endswith('.fast5'):\n",
        "        fast5_matches.append(os.path.join(path, f))\n",
        "      elif f.lower().endswith('.pod5'):\n",
        "        pod5_matches.append(os.path.join(path, f))\n",
        "      elif f.lower().endswith('.fastq') or f.lower().endswith('.fq'):\n",
        "        fastq_matches.append(os.path.join(path, f))\n",
        "      elif f.lower().endswith('fastq.gz') or f.lower().endswith('.fq.gz'):\n",
        "        fastq_zip_matches.append(os.path.join(path, f))\n",
        "  return len(pod5_matches), len(fast5_matches), len(fastq_matches), len(fastq_zip_matches)\n",
        "\n",
        "num_pod5_files, num_fast5_files, num_fastq_files, num_fastq_zip_files = count_input_files(data_dir_top)[0], count_input_files(data_dir_top)[1], count_input_files(data_dir_top)[2], count_input_files(data_dir_top)[3]\n",
        "if np.any([num_pod5_files, num_fast5_files, num_fastq_files, num_fastq_zip_files]) == False:\n",
        "  raise FileNotFoundError(f'No input file is found from {data_dir}')\n",
        "\n",
        "if data_type == 'fast5':\n",
        "  print(f'=> {num_fast5_files} FAST5 files are found.')\n",
        "  if not os.path.isdir(f'{data_dir_top}/pod5'):\n",
        "    print(f'=> FAST5 to POD5 conversion started..')\n",
        "    !pod5 convert fast5 \"$data_dir_top/\" -r --output \"$data_dir_top/pod5/\" --one-to-one \"$data_dir_top/\"\n",
        "    print(f'=> {num_fast5_files} FAST5 files are coverted to POD5 files successfully.')\n",
        "  else:\n",
        "    print(f'=> The FAST5 files were converted to POD5 files already.')\n",
        "\n",
        "elif data_type == 'pod5':\n",
        "  print(f'=> {num_pod5_files} POD5 files are found.')\n",
        "elif data_type == 'fastq':\n",
        "  fastq_zip = os.path.join(OUTPUT_DIR_S, 'basecall.fastq.gz')\n",
        "  print(f'=> {num_fastq_files} FASTQ files are found')\n",
        "  if not os.path.exists(fastq_zip):\n",
        "    if num_fastq_files >= 1 and num_fastq_zip_files == 0:\n",
        "      !cat $(find \"$data_dir_top\" -name '*.fastq') | gzip -c /dev/stdin > $fastq_zip\n",
        "      print('FASTQ files are gzipped into one FASTQ file.')\n",
        "    elif num_fastq_zip_files >= 1:\n",
        "      !zcat $(find \"$data_dir_top\" -name '*.fastq.gz') | gzip -c /dev/stdin > $fastq_zip\n",
        "  print(f'=> {num_fastq_zip_files} zipped FASTQ files are found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eldhy6Ry3eNE"
      },
      "outputs": [],
      "source": [
        "#@title Extracting on-target reads\n",
        "\n",
        "#@markdown - Basecall and align roughly for extracting on-target reads.\n",
        "\n",
        "if not os.path.exists(f'{OUTPUT_DIR_S}/dorado'):\n",
        "  !mkdir -p $OUTPUT_DIR_S/dorado\n",
        "\n",
        "rough_basecall_output = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-basecalled.bam')\n",
        "DEMUX_DIR = os.path.join(OUTPUT_DIR_S, 'dorado', 'demux')\n",
        "rough_basecall_demux_output = os.path.join(OUTPUT_DIR_S, 'dorado', 'demux', f'{barcode_kit}_{barcode_num}.bam')\n",
        "rough_basecall_output_fastq = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-basecalled.fastq.gz')\n",
        "rough_align_output = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-aligned.bam')\n",
        "rough_basecall_summary = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-basecalled.summary.txt')\n",
        "rough_align_sorted_output = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-aligned.sorted.bam')\n",
        "rough_align_output_index = os.path.join(OUTPUT_DIR_S, 'dorado', 'roughly-aligned.sorted.bam.bai')\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR_T):\n",
        "  !mkdir -p $OUTPUT_DIR_T\n",
        "\n",
        "align_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.bam')\n",
        "align_output_sorted = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.sorted.bam')\n",
        "align_output_sorted_index = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.sorted.bam.bai')\n",
        "\n",
        "ontarget_readID_list = os.path.join(OUTPUT_DIR_T, 'on-target_readIDs.txt')\n",
        "\n",
        "if NEW_TARGET == False:\n",
        "  pattern_file = os.path.join(REPEATHMM_DIR, 'bin', 'reference_sts', 'hg38', 'hg38.predefined.pa')\n",
        "  with open(pattern_file) as pat_file:\n",
        "    for line in pat_file:\n",
        "      region_info = line.split(',')\n",
        "      if region_info[0] == target_gene_lower:\n",
        "        chr = str(region_info[1])\n",
        "        start_pos = int(region_info[2]) - 5000\n",
        "        end_pos = int(region_info[3]) + 5000\n",
        "  target_region = chr + ':' + str(start_pos) + '-' + str(end_pos)\n",
        "else:\n",
        "  target_region = chromosome + ':' + str(start_position) + '-' + str(end_position)\n",
        "\n",
        "# --- 1. Process FASTQ data (No Basecalling) ---\n",
        "if data_type == 'fastq':\n",
        "    print('=> FASTQ data detected. Skipping basecalling.')\n",
        "\n",
        "    # Aligner input depends on whether barcodes are present\n",
        "    if barcode_multiplexing:\n",
        "        print('=> Barcode multiplexing enabled.')\n",
        "        if not os.path.isdir(DEMUX_DIR):\n",
        "            os.makedirs(DEMUX_DIR)\n",
        "        if not os.path.exists(rough_basecall_demux_output):\n",
        "            print('=> Demultiplexing FASTQ...')\n",
        "            !$dorado demux --kit-name $barcode_kit --output-dir $DEMUX_DIR $fastq_zip\n",
        "\n",
        "        # Run summary for multiplexed FASTQ\n",
        "        if not os.path.exists(rough_basecall_summary):\n",
        "            !$dorado summary $rough_basecall_demux_output > $rough_basecall_summary\n",
        "\n",
        "        aligner_input = rough_basecall_demux_output\n",
        "\n",
        "    else: # No barcode multiplexing\n",
        "        print('=> No barcode multiplexing.')\n",
        "        aligner_input = fastq_zip\n",
        "\n",
        "    # --- Common alignment steps for FASTQ ---\n",
        "    print('=> Alignment started..')\n",
        "    if not os.path.exists(rough_align_output):\n",
        "        !$dorado aligner -t 5 -I 6G -k 20 -w 30 $refgenome_index_w30 $aligner_input > $rough_align_output\n",
        "    if not os.path.exists(rough_align_sorted_output):\n",
        "        !$lab_command_prefix samtools sort -o $rough_align_sorted_output $rough_align_output\n",
        "    if not os.path.exists(rough_align_output_index):\n",
        "        !$lab_command_prefix samtools index $rough_align_sorted_output\n",
        "\n",
        "    # --- Common On-target BAM extraction for FASTQ ---\n",
        "    if not os.path.exists(align_output):\n",
        "        !$lab_command_prefix samtools view $rough_align_sorted_output \"$target_region\" -b > $align_output\n",
        "    if not os.path.exists(align_output_sorted):\n",
        "        !$lab_command_prefix samtools sort -o $align_output_sorted $align_output\n",
        "    if not os.path.exists(align_output_sorted_index):\n",
        "        !$lab_command_prefix samtools index $align_output_sorted\n",
        "\n",
        "\n",
        "# --- 2. Process POD5 / FAST5 data (Includes Basecalling) ---\n",
        "elif data_type in ['pod5', 'fast5']:\n",
        "\n",
        "    # Step 1: Set Basecaller input path (the only difference between pod5 and fast5)\n",
        "    if data_type == 'pod5':\n",
        "        basecaller_input_dir = data_dir_top\n",
        "    else: # data_type == 'fast5'\n",
        "        # The original code used the pod5 directory for fast5, so we keep that logic.\n",
        "        basecaller_input_dir = f\"{data_dir_top}/pod5/\"\n",
        "\n",
        "    # Step 2: Run Basecalling\n",
        "    if not os.path.exists(rough_basecall_output):\n",
        "        print('=> Basecalling started..')\n",
        "        !$dorado basecaller -x cuda:all --emit-sam -r \\\n",
        "        \"$dorado_top_dir/basecalling_models/$dorado_rough_model/\" \"$data_dir_top/\" | $lab_command_prefix samtools view -b -o $rough_basecall_output\n",
        "\n",
        "    # Step 3: Demultiplexing (if needed) and setting input for the next steps\n",
        "    if barcode_multiplexing:\n",
        "        print('=> Barcode multiplexing enabled.')\n",
        "        if not os.path.isdir(DEMUX_DIR):\n",
        "            os.makedirs(DEMUX_DIR)\n",
        "        if not os.path.exists(rough_basecall_demux_output):\n",
        "            print('=> Demultiplexing BAM...')\n",
        "            !$dorado demux --kit-name $barcode_kit --output-dir $DEMUX_DIR $rough_basecall_output\n",
        "\n",
        "        # If demux is active, the next steps (summary, aligner) use the demux result as input\n",
        "        summary_input = rough_basecall_demux_output\n",
        "        aligner_input = rough_basecall_demux_output\n",
        "\n",
        "    else: # No barcode multiplexing\n",
        "        print('=> No barcode multiplexing.')\n",
        "        # If no demux, the next steps use the original basecall result as input\n",
        "        summary_input = rough_basecall_output\n",
        "        aligner_input = rough_basecall_output\n",
        "\n",
        "    # --- Common subsequent steps for pod5/fast5 ---\n",
        "\n",
        "    # Step 4: Summary\n",
        "    if not os.path.exists(rough_basecall_summary):\n",
        "        print('=> Summarize basecall results.')\n",
        "        !$dorado summary $summary_input > $rough_basecall_summary\n",
        "\n",
        "    # Step 5: Alignment\n",
        "    if not os.path.exists(rough_align_output):\n",
        "        print('=> Alignment (rough).')\n",
        "        !$dorado aligner -t 5 -I 6G -k 20 -w 30 $refgenome_index_w30 $aligner_input > $rough_align_output\n",
        "\n",
        "    # Step 6: Sort & Index\n",
        "    if not os.path.exists(rough_align_sorted_output):\n",
        "        print('=> Alignment file sorting..')\n",
        "        !$lab_command_prefix samtools sort -o $rough_align_sorted_output $rough_align_output\n",
        "    if not os.path.exists(rough_align_output_index):\n",
        "        print('=> Alignment file indexing..')\n",
        "        !$lab_command_prefix samtools index $rough_align_sorted_output\n",
        "\n",
        "    # Step 7: Extract On-target Read IDs\n",
        "    if not os.path.exists(ontarget_readID_list):\n",
        "        print('=> Extracting on-target read IDs..')\n",
        "        !$lab_command_prefix samtools view $rough_align_sorted_output \"$target_region\" | cut -f1 | sort | uniq > $ontarget_readID_list\n",
        "\n",
        "\n",
        "# --- 3. Final completion check (Only for pod5/fast5 path) ---\n",
        "if os.path.exists(ontarget_readID_list):\n",
        "    print(\"=> On-target read IDs extraction successfully completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SF3rGbwkjjs7"
      },
      "outputs": [],
      "source": [
        "#@title Basecalling\n",
        "\n",
        "#@markdown - Convert raw signal to DNA base.\n",
        "#@markdown - `INPUT` : pod5 files or fast5 files that are converted to pod5 files in the input directory `data_dir`.\n",
        "#@markdown - `OUTPUT` : fastq files. You can find them at `repeatlab/analysis/[sample_name]/dorado/`.\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR_T/dorado\n",
        "basecall_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'basecalled.bam')\n",
        "# basecall_5mC_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'basecalled_5mC.bam')\n",
        "\n",
        "if data_type == 'pod5':\n",
        "  if not os.path.exists(basecall_output):\n",
        "    print('Basecalling started..')\n",
        "    !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 80000 --batchsize 32 \\\n",
        "     --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_model/\" \\\n",
        "     -l $ontarget_readID_list \"$data_dir_top/\" | $lab_command_prefix samtools view -b -o $basecall_output\n",
        "  # if not os.path.exists(basecall_5mC_output):\n",
        "  #   !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 80000 --batchsize 32 \\\n",
        "  #    --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "  #    --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "  #    -l $ontarget_readID_list \"$data_dir_top/\" | $lab_command_prefix samtools view -b -o $basecall_5mC_output\n",
        "\n",
        "elif data_type == 'fast5':\n",
        "  if not os.path.exists(basecall_output):\n",
        "    print('Basecalling started..')\n",
        "    !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 80000 --batchsize 32 \\\n",
        "     --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_model/\" \\\n",
        "     -l $ontarget_readID_list \"$data_dir_top/pod5/\" | $lab_command_prefix samtools view -b -o $basecall_output\n",
        "  # if not os.path.exists(basecall_5mC_output):\n",
        "  #   !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 80000 --batchsize 32 \\\n",
        "  #    --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "  #    --emit-sam --emit-moves -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "  #    -l $ontarget_readID_list \"$data_dir_top/pod5/\" | $lab_command_prefix samtools view -b -o $basecall_5mC_output\n",
        "\n",
        "elif data_type == 'fastq':\n",
        "  print('FASTQ input data does not need basecalling.')\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hUeIGSoc4Guj"
      },
      "outputs": [],
      "source": [
        "#@title Mapping the sequence reads\n",
        "\n",
        "#@markdown - Align sequencing data to reference genome sequence to find where the sequences came from.\n",
        "#@markdown - `INPUT` : a bam file basecalled at 'Basecalling' process.\n",
        "#@markdown - `OUTPUT` : a sorted bam file, and its index file. You can find it at `repeatlab/analysis/{sample_name}/dorado/aligned.sorted.bam`.\n",
        "\n",
        "align_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.bam')\n",
        "align_output_sorted = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.sorted.bam')\n",
        "align_output_sorted_index = os.path.join(OUTPUT_DIR_T, 'dorado', 'aligned.sorted.bam.bai')\n",
        "\n",
        "\n",
        "if data_type == 'pod5' or data_type == 'fast5':\n",
        "  if os.path.exists(align_output_sorted):\n",
        "    print('Alignment already done.')\n",
        "  else:\n",
        "    print('Alignment started..')\n",
        "    print('Alignment takes a few minutes. Please wait.')\n",
        "    !$dorado aligner -t 5 $refgenome_index $basecall_output | $lab_command_prefix samtools sort -o $align_output_sorted /dev/stdin\n",
        "    print('Alignment successfully done.')\n",
        "\n",
        "  if not os.path.exists(align_output_sorted_index):\n",
        "    !$lab_command_prefix samtools index $align_output_sorted\n",
        "\n",
        "elif data_type == 'fastq':\n",
        "  print('FASTQ input data does not need additional mapping.')\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "px6CxqMv8mxB"
      },
      "outputs": [],
      "source": [
        "#@title Running RepeatHMM\n",
        "\n",
        "#@markdown - Running 'RepeatHMM'. \\\n",
        "#@markdown - `INPUT` : a bam file created at 'Mapping' step. \\\n",
        "#@markdown - `OUTPUT` : a result log file which contains information about repeats. \\\n",
        "#@markdown You can find it at `repeatlab/analysis/{sample_name}/{target_gene}/RepeatHMM/rhmm_result.log`.\n",
        "\n",
        "print('Repeat count calculation started..')\n",
        "\n",
        "rhmm_output = os.path.join(OUTPUT_DIR_T, 'repeatHMM', 'rhmm_result.log')\n",
        "tmpdir = os.path.join(OUTPUT_DIR_T, 'tmp')\n",
        "logbam = 'logbam'\n",
        "pattern_file = os.path.join(REPEATHMM_DIR, 'bin', 'reference_sts', 'hg38', 'hg38.predefined.pa')\n",
        "original_output = os.path.join(f'{logbam}/RepBAM_{target_gene}.gmm*.log')\n",
        "\n",
        "if not os.path.isdir(tmpdir):\n",
        "  os.makedirs(tmpdir)\n",
        "if os.path.isdir(logbam):\n",
        "  !rm -rf $logbam\n",
        "  os.makedirs(logbam)\n",
        "if not os.path.exists(rhmm_output):\n",
        "  !conda run --no-capture-output -n rhmm python2.7 $REPEATHMM_DIR/bin/repeatHMM.py BAMinput --repeatName $target_gene \\\n",
        "  --GapCorrection 1 --FlankLength 30 --UserDefinedUniqID $sample_name-$target_gene \\\n",
        "  --Onebamfile $align_output_sorted --outFolder $tmpdir/ --Patternfile $pattern_file --hgfile $refgenome_fasta --SplitAndReAlign 2 --SeqTech Nanopore --outlog DEBUG\n",
        "  !mkdir -p $OUTPUT_DIR_T/repeatHMM\n",
        "  !mv $original_output $rhmm_output\n",
        "\n",
        "print('DONE')\n",
        "print(f'Result log file is in {rhmm_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9iv9rdddV2jX"
      },
      "outputs": [],
      "source": [
        "#@title Methylation profiling\n",
        "\n",
        "#@markdown - Align sequences to reference genome before methylation profiling.\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "\n",
        "if data_type == 'fastq':\n",
        "  print('FASTQ input does not offer methylation profiling.')\n",
        "\n",
        "elif data_type == 'pod5' or 'fast5':\n",
        "\n",
        "  allele1_readID = os.path.join(OUTPUT_DIR_T, 'allele1_readIDs.txt')\n",
        "  allele2_readID = os.path.join(OUTPUT_DIR_T, 'allele2_readIDs.txt')\n",
        "\n",
        "  # Clustering the reads for phasing\n",
        "  NUM_ALLELES = 2\n",
        "  sample_reads = {}\n",
        "\n",
        "  with open(rhmm_output) as f:\n",
        "    for line in f:\n",
        "      if line.startswith('INFO: READ:'):\n",
        "        fragments = line.split(' ')\n",
        "        if fragments[2] == 'Status:True':\n",
        "          repeat_count = int(fragments[3][11:])\n",
        "          if repeat_count != 0:\n",
        "            read_id = fragments[1][5:]\n",
        "            sequence = fragments[6][7:]\n",
        "            pattern = fragments[5][9:]\n",
        "            sample_reads[read_id] = [repeat_count, sequence]\n",
        "\n",
        "  sample_reads_df = pd.DataFrame(sample_reads).T.reset_index().sort_values(by=[0])\n",
        "  sample_reads_df.columns = ['read_id', 'repeat_count', 'sequence']\n",
        "  sample_reads_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  rc = sample_reads_df['repeat_count'].to_list()\n",
        "  sample_repeats = np.array(rc)\n",
        "  l10_sample_repeats = np.log10(sample_repeats)\n",
        "  sample_gmm = GaussianMixture(NUM_ALLELES).fit(l10_sample_repeats[:, np.newaxis])\n",
        "  gmm_labels = np.argsort(sample_gmm.means_.ravel())\n",
        "  gmmidx2label = {gmmidx: label for label, gmmidx in enumerate(gmm_labels)}\n",
        "  gmm_means = sample_gmm.means_[gmm_labels]\n",
        "  pred_labels = np.array([gmmidx2label[p] for p in sample_gmm.predict(l10_sample_repeats[:, np.newaxis])])\n",
        "  allele_repeats = 10 ** gmm_means\n",
        "\n",
        "  sample_reads_df.insert(2, 'allele', pred_labels)\n",
        "\n",
        "  allele1_reads = sample_reads_df[sample_reads_df['allele'] == 0]['read_id'].to_list()\n",
        "  allele2_reads = sample_reads_df[sample_reads_df['allele'] == 1]['read_id'].to_list()\n",
        "\n",
        "  # Write down read IDs for each allele\n",
        "  with open(allele1_readID, 'w') as f:\n",
        "      for read in allele1_reads:\n",
        "          f.write(read + '\\n')\n",
        "\n",
        "  with open(allele2_readID, 'w') as f:\n",
        "      for read in allele2_reads:\n",
        "          f.write(read + '\\n')\n",
        "\n",
        "  # basecalling with 5mCG model\n",
        "  allele1_basecall_5mC_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele1_basecalled_5mC.bam')\n",
        "  allele2_basecall_5mC_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele2_basecalled_5mC.bam')\n",
        "\n",
        "  if data_type == 'pod5':\n",
        "    if not os.path.exists(allele1_basecall_5mC_output) or not os.path.exists(allele2_basecall_5mC_output):\n",
        "      !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 70000 --batchsize 64 \\\n",
        "      --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "      --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "      -l $allele1_readID \"$data_dir_top/\" | $lab_command_prefix samtools view -b -o $allele1_basecall_5mC_output\n",
        "      !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 70000 --batchsize 64 \\\n",
        "      --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "      --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "      -l $allele2_readID \"$data_dir_top/\" | $lab_command_prefix samtools view -b -o $allele2_basecall_5mC_output\n",
        "\n",
        "  elif data_type == 'fast5':\n",
        "    if not os.path.exists(allele1_basecall_5mC_output) or not os.path.exists(allele2_basecall_5mC_output):\n",
        "      !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 70000 --batchsize 64 \\\n",
        "      --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "      --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "      -l $allele1_readID \"$data_dir_top/pod5/\" | $lab_command_prefix samtools view -b -o $allele1_basecall_5mC_output\n",
        "      !$dorado basecaller -x cuda:all --min-qscore 6 --chunksize 70000 --batchsize 64 \\\n",
        "      --modified-bases-models \"$dorado_top_dir/basecalling_models/$dorado_5mC_model/\" \\\n",
        "      --emit-sam -r \"$dorado_top_dir/basecalling_models/$dorado_original_model/\" \\\n",
        "      -l $allele2_readID \"$data_dir_top/pod5/\" | $lab_command_prefix samtools view -b -o $allele2_basecall_5mC_output\n",
        "\n",
        "  # mapping\n",
        "  allele1_alignment_5mC_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele1_alignments_5mC.bam')\n",
        "  allele2_alignment_5mC_output = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele2_alignments_5mC.bam')\n",
        "  allele1_alignment_5mC_output_sorted = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele1_alignments_5mC.sorted.bam')\n",
        "  allele2_alignment_5mC_output_sorted = os.path.join(OUTPUT_DIR_T, 'dorado', 'allele2_alignments_5mC.sorted.bam')\n",
        "\n",
        "  if not os.path.exists(allele1_alignment_5mC_output_sorted):\n",
        "    !$dorado aligner -t 20 $refgenome_index $allele1_basecall_5mC_output > $allele1_alignment_5mC_output\n",
        "    !$lab_command_prefix samtools sort --write-index -o $allele1_alignment_5mC_output_sorted $allele1_alignment_5mC_output\n",
        "    !rm $allele1_alignment_5mC_output\n",
        "\n",
        "  if not os.path.exists(allele2_alignment_5mC_output_sorted):\n",
        "    !$dorado aligner -t 20 $refgenome_index $allele2_basecall_5mC_output > $allele2_alignment_5mC_output\n",
        "    !$lab_command_prefix samtools sort --write-index -o $allele2_alignment_5mC_output_sorted $allele2_alignment_5mC_output\n",
        "    !rm $allele2_alignment_5mC_output\n",
        "\n",
        "  # methylation profiling\n",
        "  !mkdir -p $OUTPUT_DIR_S/methylation\n",
        "  !mkdir -p $OUTPUT_DIR_T/methylation\n",
        "  tmp_refgenome = os.path.join(OUTPUT_DIR_S, 'methylation', 'refgenome.fa.gz')\n",
        "  extracted_refgenome = os.path.join(OUTPUT_DIR_T, 'methylation', 'target_refgenome.fa')\n",
        "  allele1_methylation_bed = os.path.join(OUTPUT_DIR_T, 'methylation', 'allele1_methylation.bedMethyl')\n",
        "  allele2_methylation_bed = os.path.join(OUTPUT_DIR_T, 'methylation', 'allele2_methylation.bedMethyl')\n",
        "  # allele1_methylation_tsv = os.path.join(OUTPUT_DIR_T, 'methylation', 'allele1_methylation.tsv')\n",
        "  # allele2_methylation_tsv = os.path.join(OUTPUT_DIR_T, 'methylation', 'allele2_methylation.tsv')\n",
        "\n",
        "  pattern_file = os.path.join(REPEATHMM_DIR, 'bin', 'reference_sts', 'hg38', 'hg38.predefined.pa')\n",
        "  target_gene_lower = f'{target_gene}'.lower()\n",
        "\n",
        "  if not os.path.exists(f'{OUTPUT_DIR_T}/others/target_region.csv'):\n",
        "    !mkdir -p $OUTPUT_DIR_T/others\n",
        "    !grep $target_gene_lower $pattern_file > $OUTPUT_DIR_T/others/target_region.csv\n",
        "\n",
        "  with open(f'{OUTPUT_DIR_T}/others/target_region.csv') as target_region_file:\n",
        "    for line in target_region_file:\n",
        "      target_chr, target_pos_start, target_pos_end = line.split(',')[1], line.split(',')[2], line.split(',')[3]\n",
        "      target_region = str(target_chr) + ':' + str(target_pos_start) + '-' + str(target_pos_end)\n",
        "\n",
        "  if not os.path.exists(allele1_methylation_bed) or not os.path.exists(allele2_methylation_bed):\n",
        "    !$lab_command_prefix gunzip -c $refgenome_fasta > $tmp_refgenome\n",
        "    !$lab_command_prefix samtools faidx $tmp_refgenome $target_chr > $extracted_refgenome\n",
        "    !chmod 755 $modkit\n",
        "    !$modkit pileup --no-filtering --combine-strands --cpg \\\n",
        "    --ref $extracted_refgenome $allele1_alignment_5mC_output_sorted $allele1_methylation_bed\n",
        "    !$modkit pileup --no-filtering --combine-strands --cpg \\\n",
        "    --ref $extracted_refgenome $allele2_alignment_5mC_output_sorted $allele2_methylation_bed\n",
        "    !rm $tmp_refgenome\n",
        "\n",
        "# if data_type == 'fastq':\n",
        "#   print('FASTQ input does not offer methylation profiling.')\n",
        "\n",
        "print('DONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGvxUslzCYl"
      },
      "source": [
        "---\n",
        "## Part C: Repeat Expansion Analysis & Results <a name=\"Results\"></a>\n",
        "\n",
        "This is the core analysis section where RepeatLab measures the repeat expansion sizes in your sample. The tool will:\n",
        "- Identify individual repeat units\n",
        "- Count the number of repeats in each read\n",
        "- Determine the repeat structure and any interruptions\n",
        "- Generate comprehensive statistics\n",
        "\n",
        "**For researchers:** This analysis distinguishes between homozygous and heterozygous expansions and can detect complex repeat patterns.\n",
        "\n",
        "### Understanding Your Results:\n",
        "\n",
        "**Repeat Count Distribution:**\n",
        "- Shows the number of repeat units found across all analyzed reads\n",
        "- Peaks in the distribution typically represent different alleles\n",
        "- For normal samples: Usually see a single peak in the normal range\n",
        "- For expanded samples: May see bimodal distribution (heterozygous) or shifted peak (homozygous)\n",
        "\n",
        "**Clinical Interpretation:**\n",
        "Compare your results with established pathogenic thresholds for your target gene (e.g., >50 CTG repeats for DM1)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data QC\n",
        "\n",
        "#@markdown - The bar plot shows how many reads have passed or failed at basecalling step.\n",
        "#@markdown - The table shows how many reads and bases are on-target.\n",
        "\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import ColumnDataSource, HoverTool, Span, Label\n",
        "from bokeh.io import output_notebook # Enable output in Colab/Jupyter environment.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pyranges as pr\n",
        "from IPython.display import display\n",
        "\n",
        "# Set Bokeh output to display directly in the notebook\n",
        "output_notebook(hide_banner=True)\n",
        "\n",
        "# Data type check\n",
        "if data_type == 'pod5' or data_type == 'fast5':\n",
        "  seq_summary = None\n",
        "\n",
        "  def process_form_summary(file_path):\n",
        "\n",
        "      seq_summary = pd.read_csv(\n",
        "          file_path, delimiter='\\t',\n",
        "          usecols=[\n",
        "              'channel', 'start_time', 'duration',\n",
        "              'sequence_length_template', 'mean_qscore_template'])\n",
        "\n",
        "      seq_summary.sort_values('start_time', inplace=True)\n",
        "      seq_summary.reset_index(drop=True, inplace=True)\n",
        "      seq_summary = seq_summary\n",
        "\n",
        "      return seq_summary\n",
        "\n",
        "  seq_summary = process_form_summary(rough_basecall_summary)\n",
        "\n",
        "  pattern_file = os.path.join(REPEATHMM_DIR, 'bin', 'reference_sts', 'hg38', 'hg38.predefined.pa')\n",
        "  target_gene_lower = f'{target_gene}'.lower()\n",
        "  !mkdir -p $OUTPUT_DIR_T/others\n",
        "  !grep $target_gene_lower $pattern_file > $OUTPUT_DIR_T/others/target_region.csv\n",
        "\n",
        "  with open(f'{OUTPUT_DIR_T}/others/target_region.bed', 'w') as f:\n",
        "    target_region_df = pd.read_csv(f'{OUTPUT_DIR_T}/others/target_region.csv', names=['gene', 'chr', 'start', 'end', 'pattern', 'strand', 'range', 'others'])\n",
        "    gene = target_region_df.loc[0, 'gene']\n",
        "    chr = target_region_df.loc[0, 'chr']\n",
        "    start = target_region_df.loc[0, 'start']\n",
        "    end = target_region_df.loc[0, 'end']\n",
        "    f.write('{}\\t{}\\t{}\\t{}'.format(chr, start, end, gene))\n",
        "\n",
        "  region_bed = None\n",
        "  target_names = None\n",
        "\n",
        "  def process_form_bed(file_path):\n",
        "\n",
        "      region_bed = pd.read_csv(\n",
        "          file_path, sep='\\t', header=None,\n",
        "          names=['chrom', 'start', 'end', 'tname'])\n",
        "\n",
        "      region_bed['region'] = [\n",
        "          '{}:{}-{}'.format(x['chrom'], x.start, x.end)\n",
        "          for _, x in region_bed.iterrows()]\n",
        "      target_names = region_bed['tname'].to_list()\n",
        "\n",
        "      return region_bed, target_names\n",
        "\n",
        "  region_bed, target_names = process_form_bed(f'{OUTPUT_DIR_T}/others/target_region.bed')\n",
        "\n",
        "  print(\"Basecall QC:\")\n",
        "  print(\"The total number of reads is:\", len(seq_summary))\n",
        "\n",
        "  seq_summary['passes_filtering'] = np.where(seq_summary['mean_qscore_template'] >= 6, True, False)\n",
        "  seq_summary.passes_filtering = seq_summary.passes_filtering.astype('category')\n",
        "  pass_fail = seq_summary.groupby('passes_filtering', observed=False).size()\n",
        "\n",
        "  print(\"The number of pass reads is:\", pass_fail[True])\n",
        "\n",
        "  #--- 1. Basecalling Pass/Fail Horizontal Bar Plot (Bokeh) ---\n",
        "  pass_percentage = 100 * pass_fail[True] / len(seq_summary)\n",
        "  values = [pass_percentage, 100 - pass_percentage]\n",
        "  classes = ['Pass', 'Fail']\n",
        "  colors = ['#54B8B1', '#EF4135']\n",
        "\n",
        "  # Create Bokeh ColumnDataSource\n",
        "  data = {'classes': classes, 'values': values, 'colors': colors}\n",
        "  source = ColumnDataSource(data=data)\n",
        "\n",
        "  # Define Hover tool\n",
        "  hover = HoverTool(tooltips=[\n",
        "      (\"Status\", \"@classes\"),\n",
        "      (\"Percentage\", \"@values{0.1f}%\") # Format to one decimal place\n",
        "  ])\n",
        "\n",
        "  # Create Bokeh figure\n",
        "  p1 = figure(\n",
        "      y_range=classes, # Set Y-axis to 'Pass', 'Fail' (for hbar)\n",
        "      height=200,\n",
        "      width=700,\n",
        "      title=\"Basecalling : Pass / Fail reads\",\n",
        "      tools=[hover, 'pan', 'wheel_zoom', 'save', 'reset'], # Add hover tool to toolbar\n",
        "      background_fill_color=\"#f4f4f4\"\n",
        "  )\n",
        "\n",
        "  # Plot horizontal bars\n",
        "  p1.hbar(y='classes', right='values', height=0.6, color='colors', source=source)\n",
        "\n",
        "  p1.xaxis.axis_label = '%age Reads'\n",
        "  p1.x_range.start = 0 # Fix X-axis start to 0\n",
        "  p1.x_range.end = 100 # Fix X-axis end to 100\n",
        "\n",
        "  # Styling (similar to aplanat)\n",
        "  p1.outline_line_color = None\n",
        "  p1.ygrid.grid_line_color = None\n",
        "  p1.border_fill_color = \"#f4f4f4\"\n",
        "\n",
        "  show(p1) # Display the plot\n",
        "\n",
        "  # Read length distribution plot\n",
        "\n",
        "  sorted_lengths = seq_summary.sequence_length_template.sort_values(ascending=False).reset_index(drop=True)\n",
        "  cumulative_length = sorted_lengths.cumsum()\n",
        "  total_bases = cumulative_length.iloc[-1]\n",
        "  mean_length = total_bases / len(seq_summary)\n",
        "  n50_index = cumulative_length.searchsorted(total_bases / 2)\n",
        "  n50_length = sorted_lengths.iloc[n50_index]\n",
        "\n",
        "  #--- 2. Read Length Distribution Histogram (Bokeh) ---\n",
        "  LOGPLOT_FOCUS_PCT = 2\n",
        "  LOGPLOT_FLANKING_VIEW = 0.05\n",
        "  datas = seq_summary.sequence_length_template # Use directly instead of [datas[0]]\n",
        "\n",
        "  ax_focus = np.percentile(datas, [LOGPLOT_FOCUS_PCT, 100 - LOGPLOT_FOCUS_PCT])\n",
        "  ax_focuswidth = ax_focus[1] - ax_focus[0]\n",
        "  ax_view = (\n",
        "    ax_focus[0] - ax_focuswidth * LOGPLOT_FLANKING_VIEW,\n",
        "    ax_focus[1] + ax_focuswidth * LOGPLOT_FLANKING_VIEW)\n",
        "\n",
        "  # Prepare data for Bokeh histogram (using np.histogram)\n",
        "  hist, edges = np.histogram(datas, bins=400, range=ax_view)\n",
        "\n",
        "  hist_data = {'top': hist, 'bottom': np.zeros_like(hist), 'left': edges[:-1], 'right': edges[1:]}\n",
        "  hist_source = ColumnDataSource(data=hist_data)\n",
        "\n",
        "  # Define Hover tool\n",
        "  h_hover = HoverTool(tooltips=[\n",
        "      (\"Read Length\", \"(@left{0,0} to @right{0,0})\"), # Format as integer\n",
        "      (\"Count\", \"@top\")\n",
        "  ])\n",
        "\n",
        "  # Create Bokeh figure\n",
        "  p2 = figure(\n",
        "      height=400,\n",
        "      width=700,\n",
        "      title=\"Read length distribution\",\n",
        "      tools=[h_hover, 'pan', 'wheel_zoom', 'box_zoom', 'save', 'reset'],\n",
        "      background_fill_color=\"#f4f4f4\"\n",
        "  )\n",
        "\n",
        "  # Plot histogram (using quad glyph)\n",
        "  p2.quad(top='top', bottom='bottom', left='left', right='right',\n",
        "          source=hist_source, color='#0084A9', line_color=None,\n",
        "          fill_alpha=0.8) # Add transparency\n",
        "\n",
        "  # Vertical lines (Span)\n",
        "  mean_span = Span(location=mean_length, dimension='height',\n",
        "                   line_color='#EF4135', line_dash='dashed', line_width=2)\n",
        "  n50_span = Span(location=n50_length, dimension='height',\n",
        "                  line_color='#54B8B1', line_dash='dashed', line_width=2)\n",
        "\n",
        "  p2.add_layout(mean_span)\n",
        "  p2.add_layout(n50_span)\n",
        "\n",
        "  # Vertical line labels (Label)\n",
        "  plot_top_y = max(hist) * 0.95 # Label Y position (data units)\n",
        "\n",
        "  mean_label = Label(x=mean_length, y=plot_top_y,\n",
        "                     text='Mean: {:.0f}'.format(mean_length),\n",
        "                     text_color='#EF4135', x_offset=5,\n",
        "                     background_fill_color='white', background_fill_alpha=0.5)\n",
        "  n50_label = Label(x=n50_length, y=plot_top_y * 0.9, # Slightly lower Y position\n",
        "                    text='N50: {}'.format(n50_length),\n",
        "                    text_color='#54B8B1', x_offset=5,\n",
        "                    background_fill_color='white', background_fill_alpha=0.5)\n",
        "\n",
        "  p2.add_layout(mean_label)\n",
        "  p2.add_layout(n50_label)\n",
        "\n",
        "  # Set axes/range\n",
        "  p2.xaxis.axis_label = 'Read Length / bases'\n",
        "  p2.yaxis.axis_label = 'Number of reads'\n",
        "  p2.x_range.start = ax_view[0]\n",
        "  p2.x_range.end = ax_view[1]\n",
        "  p2.border_fill_color = \"#f4f4f4\"\n",
        "  p2.outline_line_color = None\n",
        "\n",
        "  show(p2) # Display the plot\n",
        "  print(\"Read length distribution:\") # Original print statement\n",
        "\n",
        "  # Alignment stats\n",
        "  align_stats = os.path.join(OUTPUT_DIR_S, 'dorado', 'aligned.stats')\n",
        "  !$ont_command_prefix stats_from_bam $rough_align_sorted_output > $align_stats\n",
        "\n",
        "  aln_summary = pd.read_csv(f'{align_stats}',\n",
        "      delimiter='\\t')\n",
        "\n",
        "  bases = aln_summary['read_length'].sum()\n",
        "\n",
        "  targets = region_bed[['chrom','start','end','tname']].rename(\n",
        "      columns={'chrom':'Chromosome','start':'Start','end':'End'}\n",
        "  )\n",
        "  targets = pr.PyRanges(targets)\n",
        "\n",
        "  reads = aln_summary.rename(\n",
        "      columns = {'ref':'Chromosome','rstart':'Start','rend':'End', 'direction':'Strand'}\n",
        "  )\n",
        "  reads = pr.PyRanges(reads)\n",
        "  ovl_summary = targets.count_overlaps(reads)\n",
        "\n",
        "  ovl = reads.count_overlaps(targets)\n",
        "  on_target = ovl[ovl.NumberOverlaps > 0]\n",
        "  non_target = ovl[ovl.NumberOverlaps == 0]\n",
        "  def summarize(df):\n",
        "      count = len(df)\n",
        "      bases = sum(df.End) - sum(df.Start)\n",
        "      ave_len = int(df.read_length.mean())\n",
        "      return count, bases // 1000, ave_len\n",
        "  on_stats = summarize(on_target)\n",
        "  non_stats = summarize(non_target)\n",
        "  all_stats = summarize(ovl)\n",
        "\n",
        "  # Targeting QC - Table\n",
        "  print('On-target reads count:')\n",
        "\n",
        "  info = pd.DataFrame([\n",
        "          on_stats, non_stats, all_stats],\n",
        "      columns=['Reads', 'Bases / k', 'Mean Read Length'],\n",
        "      index=['On-target', 'Non-target', 'All'],\n",
        "      ).transpose()\n",
        "  display(info)\n",
        "\n",
        "elif data_type == 'fastq':\n",
        "  !mkdir -p $OUTPUT_DIR_T/others\n",
        "  print('FASTQ input does not offer sequencing run QC.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YpTnIh5kn1Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BCRLkQkQJBKC"
      },
      "outputs": [],
      "source": [
        "#@title Repeat size estimation\n",
        "\n",
        "#@markdown - Visualizing distribution of repeat size from the results of running RepeatHMM. \\\n",
        "#@markdown a. The table shows read counts per repeat size. \\\n",
        "#@markdown b. The histogram shows the distribution of repeat size for each allele.\n",
        "\n",
        "import numpy as np #\n",
        "import pandas as pd #\n",
        "import re #\n",
        "import matplotlib.pyplot as plt #\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.mixture import GaussianMixture #\n",
        "import scipy.stats as stats\n",
        "from scipy import optimize\n",
        "from itertools import chain\n",
        "\n",
        "\n",
        "NUM_ALLELES = 2\n",
        "\n",
        "input_log = rhmm_output\n",
        "p2hmm_pat = re.compile('INFO: *p2bamhmm (.*)')\n",
        "logcontent = open(input_log).read()\n",
        "\n",
        "# Get the sample id\n",
        "sampleid = sample_name\n",
        "\n",
        "# Get the gene name and repeat counts\n",
        "p2hmm_found = p2hmm_pat.search(logcontent)\n",
        "p2hmminfo = eval(p2hmm_found.groups()[0])\n",
        "gene = target_gene\n",
        "repcounts = [\n",
        "    tuple(map(int, inst.rstrip(',').split(':')))\n",
        "    for inst in p2hmminfo[3].split(':', 1)[1].split(' ')]\n",
        "rc = list(chain(*[[length] * count for length, count in repcounts]))\n",
        "rc = [r for r in rc if r != 0]   # remove 0\n",
        "\n",
        "# Fit a Gaussian mixture model to the loaded repeat counts\n",
        "sample_repeats = np.array(rc)\n",
        "l10_sample_repeats = np.log10(sample_repeats)\n",
        "\n",
        "def GMM_clustering(l10_sample_repeats, NUM_ALLELES):\n",
        "    sample_gmm = GaussianMixture(NUM_ALLELES, random_state=1).fit(l10_sample_repeats[:, np.newaxis])\n",
        "    gmm_labels = np.argsort(sample_gmm.means_.ravel())\n",
        "    gmmidx2label = {gmmidx: label for label, gmmidx in enumerate(gmm_labels)}\n",
        "    gmm_means = sample_gmm.means_[gmm_labels]\n",
        "    pred_labels = np.array([gmmidx2label[p] for p in sample_gmm.predict(l10_sample_repeats[:, np.newaxis])])\n",
        "\n",
        "    return sample_gmm, gmm_labels, gmmidx2label, gmm_means, pred_labels\n",
        "\n",
        "sample_gmm, gmm_labels, gmmidx2label, gmm_means, pred_labels = GMM_clustering(l10_sample_repeats, NUM_ALLELES)\n",
        "\n",
        "label_matched_repeats = []\n",
        "for repeat, label in zip(l10_sample_repeats, pred_labels):\n",
        "    label_matched_repeats.append([repeat, label])\n",
        "round_num = 1\n",
        "\n",
        "while list(pred_labels).count(0) / len(pred_labels) < 0.1 or list(pred_labels).count(1) / len(pred_labels) < 0.1:\n",
        "  if list(pred_labels).count(0) / len(pred_labels) < 0.1:\n",
        "    l10_sample_repeats = np.array([repeat for repeat, label in label_matched_repeats if label == 1])\n",
        "  elif list(pred_labels).count(1) / len(pred_labels) < 0.1:\n",
        "    l10_sample_repeats = np.array([repeat for repeat, label in label_matched_repeats if label == 0])\n",
        "  sample_gmm, gmm_labels, gmmidx2label, gmm_means, pred_labels = GMM_clustering(l10_sample_repeats, NUM_ALLELES)\n",
        "  label_matched_repeats = []\n",
        "  for repeat, label in zip(l10_sample_repeats, pred_labels):\n",
        "    label_matched_repeats.append([repeat, label])\n",
        "  round_num += 1\n",
        "  if round_num > 3:\n",
        "    break\n",
        "\n",
        "if len(set(pred_labels)) == 1:\n",
        "    pred_labels = np.array([0] * (len(pred_labels)//2) + [1] * (len(pred_labels) - len(pred_labels)//2))\n",
        "\n",
        "removed = [l for l in rc if l not in list(np.around(10**l10_sample_repeats).astype(int))]\n",
        "sample_repeats = list(np.around(10**l10_sample_repeats).astype(int))\n",
        "\n",
        "# Plotting\n",
        "BINS = 25\n",
        "ALLELE_SHADE_COLORS = ['#FBC5C5', '#C7D36F']\n",
        "ALLELE_MARKER_COLORS = ['#ff0000', '#008000']\n",
        "\n",
        "LOGPLOT_FOCUS_PCT = 2\n",
        "LOGPLOT_BAR_MARGIN = 0.1\n",
        "LOGPLOT_FLANKING_VIEW = 0.05\n",
        "LOGPLOT_DROP_SPINES = 5\n",
        "LOGPLOT_PDF_ADDITIONAL_SCALE = 1\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(7, 3))\n",
        "\n",
        "plt.suptitle('{}_{}'.format(sampleid, gene), y=1.3, fontsize=23, fontweight='bold')\n",
        "plt.subplots_adjust(wspace=0.4)\n",
        "\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "plt.rcParams['savefig.facecolor']='white'\n",
        "\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Set up the ranges to compute histogram and to show\n",
        "ax_focus = np.percentile(l10_sample_repeats, [LOGPLOT_FOCUS_PCT, 100 - LOGPLOT_FOCUS_PCT])\n",
        "ax_focuswidth = ax_focus[1] - ax_focus[0]\n",
        "ax_view = (\n",
        "    ax_focus[0] - ax_focuswidth * LOGPLOT_FLANKING_VIEW,\n",
        "    ax_focus[1] + ax_focuswidth * LOGPLOT_FLANKING_VIEW)\n",
        "\n",
        "# Plot the histogram for each allele and annotate with the stats\n",
        "prevcount = np.zeros(BINS)\n",
        "totalreads = len(sample_repeats)\n",
        "for i, shadecolor, markercolor in zip(range(NUM_ALLELES), ALLELE_SHADE_COLORS, ALLELE_MARKER_COLORS):\n",
        "    l10counts_allele = l10_sample_repeats[pred_labels == i]\n",
        "    mediancount = np.around(10 ** np.median(l10counts_allele))\n",
        "\n",
        "    # Plot histogram\n",
        "    count, left = np.histogram(l10counts_allele, bins=BINS, range=ax_focus)\n",
        "    margin = (left[1] - left[0]) * LOGPLOT_BAR_MARGIN\n",
        "    barleft = 10 ** (left[:-1] + margin/2)\n",
        "    ax.bar(barleft, count,\n",
        "            width=10 ** (left[1:] - margin) - barleft,\n",
        "            color=shadecolor, bottom=prevcount, edgecolor=markercolor, linewidth=.5)\n",
        "    prevcount = count + prevcount\n",
        "\n",
        "    # Mark the cluster centers\n",
        "    ax.axvline(mediancount, c=markercolor, linewidth=1.5, ls='--')\n",
        "    ax.annotate('*', (mediancount, 0), fontsize=16,\n",
        "                color=markercolor, ha='center', va='center',\n",
        "                textcoords='offset points', xytext=(0, -8))\n",
        "    if i==0:\n",
        "      ha_loc = 'right'\n",
        "    elif i==1:\n",
        "      ha_loc = 'left'\n",
        "    ax.annotate(f'Allele #{i+1}\\nmedian={mediancount:g}\\n{len(l10counts_allele):} reads',\n",
        "                (mediancount, 1), xycoords=('data', 'axes fraction'),\n",
        "                xytext=(0, 7), textcoords='offset points', ha=ha_loc, va='bottom', fontsize=14,\n",
        "                bbox={'boxstyle': 'round', 'facecolor': shadecolor, 'alpha': 0.8})\n",
        "\n",
        "# Find the optimal scaling factor for the dist plot to overlay under the histogram\n",
        "barcenters = (left[1:] + left[:-1]) / 2\n",
        "barprobs = np.exp(sample_gmm.score_samples(barcenters[:, None]))\n",
        "def evaluate_scaling(x):\n",
        "    return np.sum((prevcount - x * barprobs) ** 2)\n",
        "prob_scale = optimize.minimize(evaluate_scaling, (1,)).x[0]\n",
        "\n",
        "# Plot the probability distribution of the GMM\n",
        "pdf_x = np.linspace(ax_view[0], ax_view[1], 200)\n",
        "pdf_y = sample_gmm.score_samples(pdf_x.reshape(-1, 1))\n",
        "ax.plot(10 ** pdf_x, np.exp(pdf_y) * prob_scale * LOGPLOT_PDF_ADDITIONAL_SCALE,\n",
        "         color='#432686', linewidth=1.5)\n",
        "\n",
        "# Adjust the aesthetics\n",
        "ax.tick_params(axis='x', labelsize=14)\n",
        "ax.tick_params(axis='y', labelsize=14)\n",
        "\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['left'].set_position(('outward', LOGPLOT_DROP_SPINES))\n",
        "ax.spines['bottom'].set_position(('outward', LOGPLOT_DROP_SPINES))\n",
        "\n",
        "ax.grid(which='major', alpha=0.5)\n",
        "ax.grid(which='minor', alpha=0.2)\n",
        "\n",
        "ax.set_xlabel('Repeat count', fontsize=18, labelpad=15)\n",
        "ax.set_ylabel('Read count', fontsize=18, labelpad=15)\n",
        "\n",
        "# Show the tick labels in the regular number format (not exponential)\n",
        "if 10**ax_view[1] - 10**ax_view[0] < 100:\n",
        "  ax.set_xticks(np.arange(np.floor(10**ax_view[0])+1, np.ceil(10**ax_view[1]),np.ceil(np.around(10**ax_view[1] - 10**ax_view[0])/10)+1))\n",
        "  ticks = ax.get_xticks()\n",
        "  ax.set_xticklabels(list(map(int, ticks)))\n",
        "else:\n",
        "  ticks = ax.get_xticks()\n",
        "  ax.set_xticks(ticks)\n",
        "  ax.set_xticklabels(list(map(int, ticks)))\n",
        "\n",
        "if len(removed) > 0:\n",
        "  print(f'** NOTICE (outlier existence)\\n : {len(removed)} read(s) of {\", \".join([str(num) for num in removed])} repeat counts is(are) considered as carryover contamination and eliminated.')\n",
        "\n",
        "# Format the raw count data for display\n",
        "output_df = pd.Series(sample_repeats).value_counts().sort_index().reset_index()\n",
        "output_df.columns = ['Repeat size', 'Read count']\n",
        "output_df['Allele'] = [\n",
        "    f'#{gmmidx2label[l] + 1}'\n",
        "    for l in sample_gmm.predict(np.log10(output_df['Repeat size'].values.reshape(-1, 1)))]\n",
        "output_df.reset_index(drop=True, inplace=True)\n",
        "output_df[['Allele', 'Repeat size', 'Read count']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h6OjA65xNuXW"
      },
      "outputs": [],
      "source": [
        "#@title Repeat structure\n",
        "\n",
        "#@markdown - You can check the exact sequence and structure of repeats.\n",
        "#@markdown - Both unabbreviated form and summarized form show randomly subsampled 30 reads only.\n",
        "#@markdown - A summarized form only shows sequences of which length below 25,000 bp. Extremely long sequences are not shown.\n",
        "#@markdown - If you want to check all reads' repeats, go and check the file at `repeatlab/analysis/'sample_name'/'sample_name-target_gene'/repeatHMM/'rhmm_result.log'`.\n",
        "#@markdown - Repeat structure results might be less accurate with FASTQ input.\n",
        "#@markdown\n",
        "\n",
        "#@markdown ####**[ Unabbreviated form ]**\n",
        "\n",
        "sample_reads = {}\n",
        "\n",
        "with open(rhmm_output) as f:\n",
        "    for line in f:\n",
        "        if line.startswith('INFO: READ:'):\n",
        "            fragments = line.split(' ')\n",
        "            if fragments[2] == 'Status:True':\n",
        "                repeat_count = int(fragments[3][11:])\n",
        "                if repeat_count != 0:\n",
        "                  read_id = fragments[1][5:]\n",
        "                  sequence = fragments[6][7:]\n",
        "                  pattern = fragments[5][9:]\n",
        "                  sample_reads[read_id] = [repeat_count, sequence]\n",
        "\n",
        "sample_reads\n",
        "sample_reads_df = pd.DataFrame(sample_reads).T.reset_index().sort_values(by=[0])\n",
        "sample_reads_df.columns = ['read_id', 'repeat_count', 'sequence']\n",
        "sample_reads_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "with open(f'{OUTPUT_DIR_T}/others/repeat_seq.fasta', 'w') as f:\n",
        "    for i in range(len(sample_reads_df)):\n",
        "        #f.write('>{}\\n{}\\n'.format(sample_reads_df.iloc[i]['read_id'], sample_reads_df.iloc[i]['sequence']))\n",
        "        f.write('>{}\\n{}\\n'.format('Read_'+str(i+1), sample_reads_df.iloc[i]['sequence']))\n",
        "\n",
        "from Bio import SeqIO\n",
        "seqs = list(SeqIO.parse(open(f'{OUTPUT_DIR_T}/others/repeat_seq.fasta'), 'fasta'))\n",
        "MAXLEN = 1000\n",
        "longestlen = min(max(len(s.seq) for s in seqs), MAXLEN)\n",
        "with open(f'{OUTPUT_DIR_T}/others/repeat_seq.fake_aln.fa', 'w') as outf:\n",
        "  for i, seq in enumerate(seqs):\n",
        "    print('>' + 'Read_' + str(i+1), file=outf)\n",
        "    print(str(seq.seq)[:MAXLEN].ljust(longestlen, '-'), file=outf)\n",
        "\n",
        "from Bio import AlignIO\n",
        "MAXLEN=1000\n",
        "fasta_file = AlignIO.read(f'{OUTPUT_DIR_T}/others/repeat_seq.fake_aln.fa', 'fasta')\n",
        "\n",
        "import sys\n",
        "from io import StringIO\n",
        "try:\n",
        "  sys.stdout, stdoutbackup = StringIO(), sys.stdout\n",
        "  alv.glimpse(fasta_file, seqtype='dna', width=MAXLEN, n_seq=30)\n",
        "  ret = sys.stdout.getvalue().splitlines()\n",
        "  ret[:-1] = sorted(ret[:-1], key=lambda l: int(l.split()[0].split('_')[1]))\n",
        "finally:\n",
        "  sys.stdout = stdoutbackup\n",
        "\n",
        "print('\\n'.join(ret))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KAZM-mHvv_4g"
      },
      "outputs": [],
      "source": [
        "#@markdown ####**[ Summarized form ]**\n",
        "\n",
        "from Bio import SeqIO\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "REPEAT_COLORS = ['\\033[34m', # bright cyan\n",
        "                 '\\033[91m', # bright red\n",
        "                 '\\033[92m', # bright green\n",
        "                 '\\033[93m', # bright yellow\n",
        "                 '\\033[94m', # bright blue\n",
        "                 '\\033[95m' # bright magenta\n",
        "                 ]\n",
        "\n",
        "def profile_tandem_repeats(seq, kmersize=2):\n",
        "  kmercounts = defaultdict(int)\n",
        "  for i in range(len(seq) - kmersize + 1):\n",
        "    kmer = seq[i:i+kmersize]\n",
        "    if '^' not in kmer: # Skip over repeat marks\n",
        "      kmercounts[kmer] += 1\n",
        "  return kmercounts\n",
        "\n",
        "pat_repmarks = re.compile('\\\\([^)]*\\\\)')\n",
        "\n",
        "def summarize_tandem_repeats(seq, kmer_short=3, kmer_long=6, minscore=6):\n",
        "  candidates = []\n",
        "\n",
        "  seq_wo_repmarks = pat_repmarks.sub('^', seq)\n",
        "  #print(seq_wo_repmarks)\n",
        "  for ksize in range(kmer_short, kmer_long + 1):\n",
        "    kmercounts = profile_tandem_repeats(seq_wo_repmarks, ksize)\n",
        "    for kmer, count in kmercounts.items():\n",
        "      if count >= minscore:\n",
        "        #repoccurrences = re.findall(f'(({kmer}){{2,}})', seq_wo_repmarks)\n",
        "        repoccurrences = re.findall(f'(({kmer}){{2,}})', seq_wo_repmarks)\n",
        "        totalreplength = sum(len(full) for full, repunit in repoccurrences)\n",
        "        if totalreplength >= minscore:\n",
        "          candidates.append([totalreplength, ksize, kmer])\n",
        "\n",
        "  if not candidates:\n",
        "    return seq\n",
        "\n",
        "  candidates.sort(key=lambda x: (-x[0], x[1]))\n",
        "\n",
        "  # Replace the occurrences of the first candidate with repeat marks\n",
        "  repeat = candidates[0][2]\n",
        "  def replace_repeat(match):\n",
        "    repcount = len(match.group(0)) // len(repeat)\n",
        "    if repcount <= 1:\n",
        "      return match.group(0)\n",
        "    else:\n",
        "      return f'({repeat}/{repcount})'\n",
        "\n",
        "  replaced = re.sub(f'({repeat})+', replace_repeat, seq)\n",
        "  if replaced == seq:\n",
        "    return seq\n",
        "  else:\n",
        "    return summarize_tandem_repeats(replaced, kmer_short, kmer_long, minscore)\n",
        "\n",
        "pat_repmarks_full = re.compile('(\\\\(([^)]*)/(\\\\d+)\\\\)|[^()/]+)')\n",
        "\n",
        "def colorize_repeats(seq):\n",
        "  # Find all repeats and their occurrences\n",
        "  repcounts = defaultdict(int)\n",
        "  for m in pat_repmarks_full.finditer(seq):\n",
        "    rep, repunit, count = m.groups()\n",
        "    if repunit is not None:\n",
        "      repcounts[repunit] += int(count)\n",
        "\n",
        "  repeats = sorted(repcounts.items(), key=lambda x: (-x[1], x[0]))\n",
        "  if len(repeats) > len(REPEAT_COLORS):\n",
        "    REPEAT_COLORS[:] = REPEAT_COLORS * 2 # reuse color scheme for another cycle\n",
        "  repeatcolors = {rep: color for (rep, cnt), color in zip(repeats, REPEAT_COLORS)}\n",
        "\n",
        "  outputs = []\n",
        "  for m in pat_repmarks_full.finditer(seq):\n",
        "    rep, repunit, count = m.groups()\n",
        "    if repunit is None or repunit not in repeatcolors:\n",
        "      outputs.append('\\033[90m' + rep + '\\033[0m')\n",
        "    else:\n",
        "      if int(count) >= 10:\n",
        "        color = repeatcolors[repunit] #+ '\\033[100m'\n",
        "        # outputs.append('\\033[1m' + '(' + color + repunit + '\\033[97m' + '/' + count + ')' + '\\033[0m')\n",
        "        outputs.append('\\033[1m' + '(' + color + repunit + '\\033[0m' + '/' + count + ')' + '\\033[0m')\n",
        "      else:\n",
        "        #color = '\\033[90m'\n",
        "        color = repeatcolors[repunit]\n",
        "\n",
        "        # outputs.append('(' + color + repunit + '\\033[97m' + '\\033[0m'+ '/' + count + ')' + '\\033[0m')\n",
        "        outputs.append('(' + color + repunit + '\\033[0m' + '\\033[0m'+ '/' + count + ')' + '\\033[0m')\n",
        "\n",
        "  return ''.join(outputs)\n",
        "\n",
        "turnover = np.bincount(pred_labels)[0]\n",
        "\n",
        "\n",
        "if len(rc) > 30:\n",
        "  subsampled_readnum = np.random.choice(len(rc), 30, replace=False)\n",
        "else:\n",
        "  subsampled_readnum = np.array([i+1 for i in range(len(rc)-1)])\n",
        "\n",
        "print('-'*50)\n",
        "print('|' + ' '*19 + ' Allele 1 ' + ' '*19+ '|')\n",
        "print('-'*50)\n",
        "\n",
        "for i, seq in enumerate(SeqIO.parse(open(f'{OUTPUT_DIR_T}/others/repeat_seq.fasta'), 'fasta')):\n",
        "  if i == turnover:\n",
        "    print('-'*50)\n",
        "    print('|' + ' '*19 + ' Allele 2 ' + ' '*19 + '|')\n",
        "    print('-'*50)\n",
        "  if len(seq.seq) < 25000 and i+1 in subsampled_readnum:\n",
        "    #print('I=', seq.seq)\n",
        "    #print(seq.id)\n",
        "    sumrep = summarize_tandem_repeats(str(seq.seq).replace('-', ''))\n",
        "    print(seq.id + '\\t' + colorize_repeats(sumrep))\n",
        "    #print('O=', colorize_repeats(sumrep))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMHJgMLCiJh4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Methylation profiling for each allele\n",
        "\n",
        "import matplotlib as mpl\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "if data_type == 'pod5' or data_type == 'fast5':\n",
        "  allele1_meth_prof = pd.read_csv(allele1_methylation_bed, sep='\\t', names=['chr', 'start_pos', 'end_pos', 'modified_base_code', 'score', 'strand', 'start', 'end', 'color', 'N_numbers'])\n",
        "  allele1_N_numbers = allele1_meth_prof['N_numbers'].str.split(' ', expand=True)\n",
        "  allele1_N_numbers.columns = ['coverage', 'fraction_modified', 'N_mod', 'N_canonical', 'N_other_mod', 'N_delete', 'N_fail', 'N_diff', 'N_nocall']\n",
        "  allele1_meth_prof = pd.concat([allele1_meth_prof, allele1_N_numbers], axis=1)\n",
        "  allele1_meth_prof = allele1_meth_prof.astype({'coverage' : 'int', 'fraction_modified' : 'float'})\n",
        "\n",
        "  allele2_meth_prof = pd.read_csv(allele2_methylation_bed, sep='\\t', names=['chr', 'start_pos', 'end_pos', 'modified_base_code', 'score', 'strand', 'start', 'end', 'color', 'N_numbers'])\n",
        "  allele2_N_numbers = allele2_meth_prof['N_numbers'].str.split(' ', expand=True)\n",
        "  allele2_N_numbers.columns = ['coverage', 'fraction_modified', 'N_mod', 'N_canonical', 'N_other_mod', 'N_delete', 'N_fail', 'N_diff', 'N_nocall']\n",
        "  allele2_meth_prof = pd.concat([allele2_meth_prof, allele2_N_numbers], axis=1)\n",
        "  allele2_meth_prof = allele2_meth_prof.astype({'coverage' : 'int', 'fraction_modified' : 'float'})\n",
        "\n",
        "  allele1_meth_prof, allele2_meth_prof = allele1_meth_prof[allele1_meth_prof['coverage'] > 5], allele2_meth_prof[allele2_meth_prof['coverage'] > 5]\n",
        "\n",
        "  if methylation_key_positions != \"\":\n",
        "    meth_key_groups = methylation_key_positions.split(\" \")\n",
        "    meth_keys = []\n",
        "    for group in meth_key_groups:\n",
        "      meth_keys.append(list(map(int, group.split(\",\"))))\n",
        "  if target_gene == 'DMPK':\n",
        "    CTCF1_sites = [int(site) for site in CTCF1_positions.split(\",\")]\n",
        "    CTCF2_sites = [int(site) for site in CTCF2_positions.split(\",\")]\n",
        "\n",
        "\n",
        "  DISCRETE_COLOR_LEVELS = 10\n",
        "  _cmap = mpl.colormaps.get_cmap('YlGnBu')\n",
        "  _cmap.set_gamma(0.6)\n",
        "  sitemarkers_cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
        "      'mycolormap', _cmap(np.linspace(0, 1, DISCRETE_COLOR_LEVELS)),\n",
        "      DISCRETE_COLOR_LEVELS)\n",
        "\n",
        "  ALLELE1_COLOR = '#444444'\n",
        "  ALLELE2_COLOR = '#e64980'\n",
        "\n",
        "  def plot_methylation_with_trend(ax, meth_prof, color, marker, allele, repeat_region):\n",
        "    ax.scatter(meth_prof['start_pos'], meth_prof['fraction_modified'], zorder=6,\n",
        "                edgecolor='none', facecolor=color,\n",
        "                s={'s': 15, 'o': 20}[marker], alpha=.8,\n",
        "                marker=marker, label=allele)\n",
        "\n",
        "    trend = sm.nonparametric.lowess(exog=meth_prof['start_pos'], endog=meth_prof['fraction_modified'], frac=0.4)\n",
        "    ax.plot(trend[:,0], trend[:,1], c=color, linewidth=1.5, linestyle='-', zorder=4)\n",
        "    ax.set_xticks(ax.get_xticks())\n",
        "    ax.set_yticks(np.arange(0,120,20))\n",
        "    ax.set_xticklabels((ax.get_xticks()/1000).astype(int), size=12)\n",
        "    ax.set_yticklabels(np.arange(0,120,20), size=12)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['left'].set_position(('outward', LOGPLOT_DROP_SPINES))\n",
        "    ax.spines['bottom'].set_position(('outward', LOGPLOT_DROP_SPINES))\n",
        "    ax.legend()\n",
        "    target_chr = repeat_region.split(':')[0]\n",
        "    repeat_window = repeat_region.split(':')[1].split('-')\n",
        "    repeat_start, repeat_end = int(repeat_window[0]), int(repeat_window[1])\n",
        "    repeat_length = repeat_end - repeat_start\n",
        "    ax.axvspan(repeat_start, repeat_end, alpha=0.3, color='#228be6')\n",
        "    ax.annotate(f'Repeat region\\n{repeat_region}', xy=(repeat_start+repeat_length/2, -15), xytext=(repeat_start+repeat_length/2, -50), ha='center', va='center', color='#228be6', annotation_clip=False, arrowprops=dict(arrowstyle=mpatches.ArrowStyle('-|>'), fc='#228be6', ec='#228be6'))\n",
        "    ax.set_xlabel(f'Genomic coordinate in {target_chr} (x1000)', size=12)\n",
        "    ax.set_ylabel('Methylation rate (%)', size=12)\n",
        "\n",
        "  fig, ax = plt.subplots(1,1, figsize=(18,3))\n",
        "\n",
        "  plot_methylation_with_trend(ax, allele1_meth_prof, ALLELE1_COLOR, 's', 'allele 1', target_region)\n",
        "  plot_methylation_with_trend(ax, allele2_meth_prof, ALLELE2_COLOR, 'o', 'allele 2', target_region)\n",
        "\n",
        "  if len(meth_keys) > 0:\n",
        "    for i, group in enumerate(meth_keys):\n",
        "      ax.axvspan(np.min(group), np.max(group), alpha=0.15, color='red')\n",
        "      ax.text(np.min(group)-80, 150, f'Locus{i+1}', fontsize=8)\n",
        "  if target_gene == 'DMPK':\n",
        "    ax.axvspan(np.min(CTCF1_sites), np.max(CTCF1_sites), alpha=0.15, color='black')\n",
        "    ax.axvspan(np.min(CTCF2_sites), np.max(CTCF2_sites), alpha=0.15, color='black')\n",
        "    ax.text(np.min(CTCF1_sites)+20, 140, 'CTCF1', fontsize=8)\n",
        "    ax.text(np.min(CTCF2_sites)-20, 140, 'CTCF2', fontsize=8)\n",
        "\n",
        "elif data_type == 'fastq':\n",
        "  print('FASTQ input does not offer methylation profiling.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown - Profiles for key regions.\n",
        "\n",
        "if target_gene == 'DMPK':\n",
        "  a1_CTCF1_meth_mean = np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(CTCF1_sites), 'fraction_modified'].tolist())\n",
        "  a1_CTCF2_meth_mean = np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(CTCF2_sites), 'fraction_modified'].tolist())\n",
        "  a1_g1_meth_mean = np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(meth_keys[0]), 'fraction_modified'].tolist())\n",
        "  a1_g2_meth_mean = np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(meth_keys[1]), 'fraction_modified'].tolist())\n",
        "  a1_g3_meth_mean = np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(meth_keys[2]), 'fraction_modified'].tolist())\n",
        "\n",
        "  a2_CTCF1_meth_mean = np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(CTCF1_sites), 'fraction_modified'].tolist())\n",
        "  a2_CTCF2_meth_mean = np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(CTCF2_sites), 'fraction_modified'].tolist())\n",
        "  a2_g1_meth_mean = np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(meth_keys[0]), 'fraction_modified'].tolist())\n",
        "  a2_g2_meth_mean = np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(meth_keys[1]), 'fraction_modified'].tolist())\n",
        "  a2_g3_meth_mean = np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(meth_keys[2]), 'fraction_modified'].tolist())\n",
        "\n",
        "  a1_keys_meth_mean = np.array([a1_CTCF1_meth_mean, a1_CTCF2_meth_mean, a1_g1_meth_mean, a1_g2_meth_mean, a1_g3_meth_mean])\n",
        "  a2_keys_meth_mean = np.array([a2_CTCF1_meth_mean, a2_CTCF2_meth_mean, a2_g1_meth_mean, a2_g2_meth_mean, a2_g3_meth_mean])\n",
        "\n",
        "elif len(meth_keys) > 0:\n",
        "  a1_keys_meth_mean = []\n",
        "  a2_keys_meth_mean = []\n",
        "  for key in meth_keys:\n",
        "    a1_keys_meth_mean.append(np.mean(allele1_meth_prof.loc[allele1_meth_prof['start_pos'].isin(key), 'fraction_modified'].tolist()))\n",
        "    a2_keys_meth_mean.append(np.mean(allele2_meth_prof.loc[allele2_meth_prof['start_pos'].isin(key), 'fraction_modified'].tolist()))\n",
        "  a1_keys_meth_mean = np.array(a1_keys_meth_mean)\n",
        "  a2_keys_meth_mean = np.array(a2_keys_meth_mean)\n",
        "\n",
        "else:\n",
        "  print('No methylation key regions.')\n",
        "\n",
        "if len(a1_keys_meth_mean) > 0 and len(a2_keys_meth_mean) > 0:\n",
        "  from matplotlib.patches import Polygon\n",
        "  from matplotlib.colors import Normalize\n",
        "  import matplotlib.cm as cm\n",
        "\n",
        "  DISCRETE_COLOR_LEVELS = 10\n",
        "  _cmap = plt.get_cmap('YlGnBu').copy()\n",
        "  _cmap.set_gamma(0.6)\n",
        "  _cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
        "      'mycolormap', _cmap(np.linspace(0, 1, DISCRETE_COLOR_LEVELS)),\n",
        "      DISCRETE_COLOR_LEVELS)\n",
        "  cmap_top = _cmap\n",
        "  cmap_bottom = _cmap\n",
        "\n",
        "  norm_top = Normalize(vmin=0, vmax=100)\n",
        "  norm_bottom = Normalize(vmin=0, vmax=100)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(5.5,2))\n",
        "\n",
        "  gap = 0.05\n",
        "\n",
        "  for i in range(len(a1_keys_meth_mean)):\n",
        "    x_left, x_right = i+gap, i+1-gap\n",
        "    y_bottom, y_top = 0, 1\n",
        "\n",
        "    coords_top_left = [(x_left, y_top), (x_left, y_bottom), (x_right, y_bottom)]\n",
        "    coords_bottom_right = [(x_right, y_top), (x_left, y_top), (x_right, y_bottom)]\n",
        "\n",
        "    poly_top = Polygon(coords_top_left, closed=True)\n",
        "    poly_bottom = Polygon(coords_bottom_right, closed=True)\n",
        "\n",
        "    val_top = a1_keys_meth_mean[i]\n",
        "    val_bottom = a2_keys_meth_mean[i]\n",
        "\n",
        "    poly_top.set_facecolor(cmap_top(norm_top(val_top)))\n",
        "    poly_bottom.set_facecolor(cmap_bottom(norm_bottom(val_bottom)))\n",
        "\n",
        "    poly_top.set_edgecolor('none')\n",
        "    poly_bottom.set_edgecolor('none')\n",
        "\n",
        "    ax.add_patch(poly_top)\n",
        "    ax.add_patch(poly_bottom)\n",
        "\n",
        "    linewidth=1\n",
        "    ax.plot([i+gap, i+1-gap], [1, 0], color='black', linewidth=linewidth, zorder=3)\n",
        "\n",
        "    ax.plot([i+gap, i+gap], [0, 1], color='black', linewidth=linewidth, zorder=3)\n",
        "    ax.plot([i+1-gap, i+1-gap], [0, 1], color='black', linewidth=linewidth, zorder=3)\n",
        "    ax.plot([i+gap, i+1-gap], [0, 0], color='black', linewidth=linewidth, zorder=3)\n",
        "    ax.plot([i+gap, i+1-gap], [1, 1], color='black', linewidth=linewidth, zorder=3)\n",
        "\n",
        "  ax.set_xlim(0, len(a1_keys_meth_mean))\n",
        "  ax.invert_yaxis()\n",
        "  ax.set_yticks([])\n",
        "\n",
        "  for axis in ['top', 'bottom', 'left', 'right']:\n",
        "    ax.spines[axis].set_visible(False)\n",
        "\n",
        "  sm_top = cm.ScalarMappable(norm=norm_top, cmap=cmap_top)\n",
        "  cbar = plt.colorbar(sm_top, ax=ax, location='bottom', pad=0.3, aspect=15, shrink=0.6)\n",
        "  cbar.set_label('Methylation rate (%)', fontsize=10)\n",
        "\n",
        "  ax.set_xticks(np.arange(len(a1_keys_meth_mean)) + 0.5)\n",
        "  if target_gene == 'DMPK':\n",
        "    labels = ['CTCF1', 'CTCF2', 'Locus1', 'Locus2', 'Locus3']\n",
        "    ax.set_xticklabels(labels, fontsize=15)\n",
        "  else:\n",
        "    labels = [f'Locus{i+1}' for i in range(len(a1_keys_meth_mean))]\n",
        "    ax.set_xticklabels(labels, fontsize=15)\n",
        "pd.DataFrame([a1_keys_meth_mean, a2_keys_meth_mean], columns=labels, index=['Allele1', 'Allele2'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ognxeGTqR-1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Detailed Instructions <a name=\"Instructions\"></a>\n",
        "\n",
        "## Quick Start Summary\n",
        "\n",
        "#### → Follow the <a href=\"#Quick Start\">⭐ three starred steps </a> at the top of the notebook:\n",
        "\n",
        "1. **Prepare your data**: Copy your POD5, FAST5, or FASTQ files to Google Drive and specify the location\n",
        "2. **Set parameters**: Enter your sample name and target gene (DMPK, CNBP, or NOP56)\n",
        "3. **Run analysis**: Click `Runtime` → `Run all` (or press `Ctrl/Cmd + F9`)\n",
        "\n",
        "---\n",
        "\n",
        "## Analysis Results\n",
        "\n",
        "- View your results in the [Part C](#Results) above\n",
        "- Includes summary statistics, repeat distribution plots, and detailed tables\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## System Requirements\n",
        "\n",
        "#### Before running RepeatLab, ensure:\n",
        "- **GPU enabled**: Go to `Runtime` → `Change runtime type` → Set `Hardware accelerator` to `T4 GPU`\n",
        "- **Sufficient storage**: At least 8GB free space in Google Drive\n",
        "- **File formats**: POD5, FAST5, or FASTQ files from Oxford Nanopore sequencing\n",
        "- **File organization**: Data files in a single folder (no spaces in folder names)\n",
        "\n",
        "---\n",
        "\n",
        "## Supported Genes\n",
        "\n",
        "RepeatLab comes pre-configured for these repeat expansion disorders:\n",
        "\n",
        "| Gene | Disease | Repeat Motif | Normal Range |\n",
        "|------|---------|--------------|-------------|\n",
        "| **DMPK** | Myotonic Dystrophy Type 1 (DM1) | CTG | 5-37 repeats |\n",
        "| **CNBP** | Myotonic Dystrophy Type 2 (DM2) | CCTG | <30 repeats |\n",
        "| **NOP56** | Spinocerebellar Ataxia Type 36 | GGCCTG | <14 repeats |\n",
        "\n",
        "**Need to analyze a different gene?** See the <a href=\"#Add Target\">Add a new target</a> section above.\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "#### Common issues and solutions:\n",
        "\n",
        "**1. \"GPU not enabled\" or slow processing**\n",
        "- Solution: `Runtime` → `Change runtime type` → `Hardware accelerator` → Select `T4 GPU`\n",
        "\n",
        "**2. \"Insufficient storage\" errors**\n",
        "- Check your Google Drive has at least 8GB free space\n",
        "- Delete old analysis results if needed\n",
        "\n",
        "**3. \"File not found\" errors**\n",
        "- Verify your file path in `data_dir` is correct\n",
        "- Ensure path starts after `MyDrive/` (e.g., `MyFolder/data/` not `content/drive/MyDrive/MyFolder/data/`)\n",
        "- Avoid spaces in folder names—use underscores instead (e.g., `my_data` not `my data`)\n",
        "\n",
        "**4. \"No files found\" errors**\n",
        "- Confirm your data files have the correct extension (.pod5, .fast5, or .fastq)\n",
        "- Check that files are directly in the specified folder, not in subfolders\n",
        "\n",
        "**5. Analysis produces unexpected results**\n",
        "- Verify you've selected the correct `target_gene`\n",
        "- Ensure your `pore_type` matches your sequencing chemistry\n",
        "- Check data quality: low-quality data may produce unreliable results\n",
        "\n",
        "**6. Runtime disconnection**\n",
        "- Google Colab may disconnect after 90 minutes of inactivity\n",
        "- If disconnected, simply run `Runtime` → `Run all` again\n",
        "- Previous system settings or analysis results are saved in Google Drive\n",
        "\n",
        "---\n",
        "\n",
        "## Expected Processing Times\n",
        "\n",
        "| Step | Typical Duration | Notes |\n",
        "|------|-----------------|-------|\n",
        "| Installation (Part A) | 5-10 minutes | One-time setup per session |\n",
        "| Processing (Part B) | 10-20 minutes | Depends on data size |\n",
        "| Results (Part C) | ~ 1 minute | Relatively quick |\n",
        "| **Total** | **20-30 minutes** | For typical sample |\n",
        "\n",
        "*Times are approximate and vary based on data size, quality, and Colab resources*\n",
        "\n",
        "---\n",
        "\n",
        "## Getting Help\n",
        "\n",
        "If you encounter errors or have questions:\n",
        "\n",
        "1. **Check the troubleshooting section** above\n",
        "2. **Review your input parameters** for typos or incorrect paths\n",
        "3. **Report issues**: If problems persist, please submit a detailed report at:\n",
        "   - GitHub Issues: [https://github.com/ChangLabSNU/RepeatLab/issues](https://github.com/ChangLabSNU/RepeatLab/issues)\n",
        "   - Include: Error messages, your parameter settings, and data type\n",
        "\n",
        "---\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use RepeatLab in your research, please cite:\n",
        "\n",
        "*Citation information to be added—check the [GitHub repository](https://github.com/ChangLabSNU/RepeatLab) for the latest citation details*\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- **GitHub Repository**: [https://github.com/ChangLabSNU/RepeatLab](https://github.com/ChangLabSNU/RepeatLab)\n",
        "- **Documentation**: See the repository README for detailed method descriptions\n",
        "- **Oxford Nanopore**: [https://nanoporetech.com](https://nanoporetech.com) for sequencing platform information\n",
        "\n",
        "---\n",
        "\n",
        "*RepeatLab is developed by the Chang Lab at Seoul National University*\n"
      ],
      "metadata": {
        "id": "jvHiJvBm8Jm5"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}